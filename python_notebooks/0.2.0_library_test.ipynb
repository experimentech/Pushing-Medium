{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15cd6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PMFlow BNN v0.2.0 Comprehensive Testing Notebook\n",
    "# ================================================\n",
    "# \n",
    "# This notebook thoroughly tests the PMFlow BNN v0.2.0 library with:\n",
    "# - Automatic hardware detection and configuration\n",
    "# - CPU core / GPU core utilization monitoring  \n",
    "# - Performance benchmarks for multi-system comparison\n",
    "# - Complete feature validation\n",
    "# - Detailed metrics collection\n",
    "\n",
    "print(\"ğŸ¯ PMFlow BNN v0.2.0 Comprehensive Testing Notebook\")\n",
    "print(\"=\"*55)\n",
    "print(\"Loading testing framework...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fde08e",
   "metadata": {},
   "source": [
    "# ğŸ–¥ï¸ System Detection & Hardware Analysis\n",
    "\n",
    "This notebook automatically detects hardware capabilities and configures PMFlow BNN accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f89e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Detection and Hardware Analysis\n",
    "import sys\n",
    "import os\n",
    "import platform\n",
    "import psutil\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Any, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Advanced hardware detection\n",
    "def detect_system_capabilities():\n",
    "    \"\"\"Comprehensive system detection with CPU/GPU core counting.\"\"\"\n",
    "    \n",
    "    print(\"ğŸ” Detecting System Capabilities...\")\n",
    "    \n",
    "    # Basic system info\n",
    "    system_info = {\n",
    "        'platform': platform.platform(),\n",
    "        'python_version': sys.version.split()[0],\n",
    "        'architecture': platform.architecture()[0],\n",
    "        'processor': platform.processor(),\n",
    "    }\n",
    "    \n",
    "    # CPU detection\n",
    "    cpu_info = {\n",
    "        'cpu_count_logical': psutil.cpu_count(logical=True),\n",
    "        'cpu_count_physical': psutil.cpu_count(logical=False),\n",
    "        'cpu_freq_max': psutil.cpu_freq().max if psutil.cpu_freq() else 'Unknown',\n",
    "        'cpu_freq_current': psutil.cpu_freq().current if psutil.cpu_freq() else 'Unknown',\n",
    "    }\n",
    "    \n",
    "    # Memory detection\n",
    "    memory = psutil.virtual_memory()\n",
    "    memory_info = {\n",
    "        'total_ram_gb': memory.total / (1024**3),\n",
    "        'available_ram_gb': memory.available / (1024**3),\n",
    "        'ram_usage_percent': memory.percent,\n",
    "    }\n",
    "    \n",
    "    # GPU detection\n",
    "    gpu_info = {\n",
    "        'cuda_available': torch.cuda.is_available(),\n",
    "        'gpu_count': torch.cuda.device_count() if torch.cuda.is_available() else 0,\n",
    "        'gpu_names': [],\n",
    "        'gpu_memory_gb': [],\n",
    "        'gpu_compute_capability': []\n",
    "    }\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            props = torch.cuda.get_device_properties(i)\n",
    "            gpu_info['gpu_names'].append(props.name)\n",
    "            gpu_info['gpu_memory_gb'].append(props.total_memory / (1024**3))\n",
    "            gpu_info['gpu_compute_capability'].append(f\"{props.major}.{props.minor}\")\n",
    "    \n",
    "    # Jetson detection\n",
    "    jetson_info = detect_jetson_nano()\n",
    "    \n",
    "    # Combine all info\n",
    "    capabilities = {\n",
    "        'system': system_info,\n",
    "        'cpu': cpu_info,\n",
    "        'memory': memory_info,\n",
    "        'gpu': gpu_info,\n",
    "        'jetson': jetson_info,\n",
    "    }\n",
    "    \n",
    "    return capabilities\n",
    "\n",
    "def detect_jetson_nano():\n",
    "    \"\"\"Detect if running on Jetson Nano with detailed specs.\"\"\"\n",
    "    jetson_info = {\n",
    "        'is_jetson': False,\n",
    "        'model': 'Unknown',\n",
    "        'tegra_version': 'Unknown',\n",
    "        'cuda_arch': 'Unknown'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Check device tree model\n",
    "        with open('/proc/device-tree/model', 'r') as f:\n",
    "            model = f.read().strip()\n",
    "            if 'jetson' in model.lower() or 'tegra' in model.lower():\n",
    "                jetson_info['is_jetson'] = True\n",
    "                jetson_info['model'] = model\n",
    "        \n",
    "        # Check Tegra version\n",
    "        if os.path.exists('/proc/device-tree/compatible'):\n",
    "            with open('/proc/device-tree/compatible', 'r') as f:\n",
    "                compatible = f.read()\n",
    "                if 'tegra210' in compatible:\n",
    "                    jetson_info['tegra_version'] = 'Tegra X1 (210)'\n",
    "                    jetson_info['cuda_arch'] = 'Maxwell (5.3)'\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return jetson_info\n",
    "\n",
    "def print_system_summary(capabilities):\n",
    "    \"\"\"Print formatted system summary.\"\"\"\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ SYSTEM SUMMARY:\")\n",
    "    print(f\"   Platform: {capabilities['system']['platform']}\")\n",
    "    print(f\"   Architecture: {capabilities['system']['architecture']}\")\n",
    "    print(f\"   Python: {capabilities['system']['python_version']}\")\n",
    "    \n",
    "    print(f\"\\nğŸ–¥ï¸  CPU INFORMATION:\")\n",
    "    print(f\"   Logical Cores: {capabilities['cpu']['cpu_count_logical']}\")\n",
    "    print(f\"   Physical Cores: {capabilities['cpu']['cpu_count_physical']}\")\n",
    "    print(f\"   Max Frequency: {capabilities['cpu']['cpu_freq_max']} MHz\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ MEMORY INFORMATION:\")\n",
    "    print(f\"   Total RAM: {capabilities['memory']['total_ram_gb']:.1f} GB\")\n",
    "    print(f\"   Available RAM: {capabilities['memory']['available_ram_gb']:.1f} GB\")\n",
    "    print(f\"   Usage: {capabilities['memory']['ram_usage_percent']:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nğŸ® GPU INFORMATION:\")\n",
    "    if capabilities['gpu']['cuda_available']:\n",
    "        print(f\"   CUDA Available: Yes\")\n",
    "        print(f\"   GPU Count: {capabilities['gpu']['gpu_count']}\")\n",
    "        for i, (name, memory, compute) in enumerate(zip(\n",
    "            capabilities['gpu']['gpu_names'],\n",
    "            capabilities['gpu']['gpu_memory_gb'],\n",
    "            capabilities['gpu']['gpu_compute_capability']\n",
    "        )):\n",
    "            print(f\"   GPU {i}: {name}\")\n",
    "            print(f\"     Memory: {memory:.1f} GB\")\n",
    "            print(f\"     Compute: {compute}\")\n",
    "    else:\n",
    "        print(f\"   CUDA Available: No\")\n",
    "    \n",
    "    if capabilities['jetson']['is_jetson']:\n",
    "        print(f\"\\nğŸ¤– JETSON INFORMATION:\")\n",
    "        print(f\"   Model: {capabilities['jetson']['model']}\")\n",
    "        print(f\"   Tegra: {capabilities['jetson']['tegra_version']}\")\n",
    "        print(f\"   CUDA Arch: {capabilities['jetson']['cuda_arch']}\")\n",
    "\n",
    "# Run system detection\n",
    "system_capabilities = detect_system_capabilities()\n",
    "print_system_summary(system_capabilities)\n",
    "\n",
    "# Determine optimal device\n",
    "if system_capabilities['gpu']['cuda_available']:\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"\\nâœ… Using GPU: {system_capabilities['gpu']['gpu_names'][0]}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(f\"\\nâœ… Using CPU: {system_capabilities['cpu']['cpu_count_logical']} logical cores\")\n",
    "\n",
    "print(f\"\\nğŸ¯ System detection complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df13f46",
   "metadata": {},
   "source": [
    "# ğŸ“š Library Import & Configuration\n",
    "\n",
    "Import PMFlow BNN library and configure based on detected hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e319b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Import and Configuration\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Method 1: Try GitHub installation (preferred after library is pushed)\n",
    "print(\"ğŸš€ Attempting to install PMFlow BNN v0.2.0 from GitHub...\")\n",
    "print(\"ğŸ“¦ Installing: pip install git+https://github.com/experimentech/Pushing-Medium.git#subdirectory=programs/demos/machine_learning/nn_lib_v2\")\n",
    "\n",
    "try:\n",
    "    import subprocess\n",
    "    \n",
    "    # Install from GitHub - Python 3.6+ compatible subprocess call\n",
    "    result = subprocess.run([\n",
    "        sys.executable, '-m', 'pip', 'install', \n",
    "        'git+https://github.com/experimentech/Pushing-Medium.git#subdirectory=programs/demos/machine_learning/nn_lib_v2'\n",
    "    ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"âœ… Successfully installed PMFlow BNN v0.2.0 from GitHub!\")\n",
    "        installation_source = \"github\"\n",
    "    else:\n",
    "        print(f\"âš ï¸ GitHub installation failed: {result.stderr}\")\n",
    "        print(\"ğŸ“‚ Falling back to local development path...\")\n",
    "        installation_source = \"local\"\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ GitHub installation error: {e}\")\n",
    "    print(\"ğŸ“‚ Falling back to local development path...\")\n",
    "    installation_source = \"local\"\n",
    "\n",
    "# Method 2: Local development fallback\n",
    "if installation_source == \"local\":\n",
    "    pmflow_library_path = '/home/tmumford/Documents/gravity/programs/demos/machine_learning/nn_lib_v2'\n",
    "    if os.path.exists(pmflow_library_path) and pmflow_library_path not in sys.path:\n",
    "        sys.path.insert(0, pmflow_library_path)\n",
    "        print(f\"ğŸ“‚ Added local library path: {pmflow_library_path}\")\n",
    "\n",
    "# Try to import PMFlow BNN\n",
    "try:\n",
    "    from pmflow_bnn import (\n",
    "        get_model_v2, \n",
    "        get_performance_config, \n",
    "        PMFlowEvaluator,\n",
    "        benchmark_temporal_parallelism,\n",
    "        validate_embarrassingly_parallel_scaling\n",
    "    )\n",
    "    print(\"âœ… PMFlow BNN library imported successfully\")\n",
    "    library_available = True\n",
    "    \n",
    "    # Get version info\n",
    "    try:\n",
    "        from pmflow_bnn.version import __version__\n",
    "        print(f\"ğŸ“¦ PMFlow BNN version: {__version__}\")\n",
    "    except:\n",
    "        print(\"ğŸ“¦ PMFlow BNN version: Development\")\n",
    "    \n",
    "    print(f\"ğŸ“ Installation source: {installation_source}\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"âŒ PMFlow BNN library not available: {e}\")\n",
    "    print(\"ğŸ“ Note: This notebook can run system detection but requires library for testing\")\n",
    "    library_available = False\n",
    "    installation_source = \"none\"\n",
    "\n",
    "# Configure based on detected hardware\n",
    "if library_available:\n",
    "    print(f\"\\nğŸ”§ Configuring PMFlow BNN for detected hardware...\")\n",
    "    \n",
    "    # Determine hardware profile\n",
    "    if system_capabilities['jetson']['is_jetson']:\n",
    "        hardware_profile = 'jetson_nano'\n",
    "        print(f\"   Hardware profile: Jetson Nano\")\n",
    "    elif system_capabilities['gpu']['gpu_count'] > 1:\n",
    "        hardware_profile = 'multi_gpu'\n",
    "        print(f\"   Hardware profile: Multi-GPU ({system_capabilities['gpu']['gpu_count']} GPUs)\")\n",
    "    elif system_capabilities['gpu']['cuda_available']:\n",
    "        hardware_profile = 'single_gpu'\n",
    "        print(f\"   Hardware profile: Single GPU\")\n",
    "    else:\n",
    "        hardware_profile = 'cpu'\n",
    "        print(f\"   Hardware profile: CPU ({system_capabilities['cpu']['cpu_count_logical']} cores)\")\n",
    "    \n",
    "    # Get optimized configuration\n",
    "    pmflow_config = get_performance_config(hardware_profile)\n",
    "    print(f\"   Model type: {pmflow_config['model_type']}\")\n",
    "    print(f\"   Centers: {pmflow_config['n_centers']}\")\n",
    "    print(f\"   PM steps: {pmflow_config['pm_steps']}\")\n",
    "    print(f\"   Temporal stages: {pmflow_config['temporal_stages']}\")\n",
    "    \n",
    "    print(f\"âœ… PMFlow BNN configured for optimal performance\")\n",
    "    \n",
    "    # Display installation instructions for other environments\n",
    "    print(f\"\\nğŸ’¡ USAGE IN OTHER ENVIRONMENTS:\")\n",
    "    print(f\"   Google Colab:\")\n",
    "    print(f\"   !pip install git+https://github.com/experimentech/Pushing-Medium.git#subdirectory=programs/demos/machine_learning/nn_lib_v2\")\n",
    "    print(f\"   \")\n",
    "    print(f\"   Jetson Nano:\")\n",
    "    print(f\"   pip install git+https://github.com/experimentech/Pushing-Medium.git#subdirectory=programs/demos/machine_learning/nn_lib_v2\")\n",
    "    print(f\"   \")\n",
    "    print(f\"   Any Python environment:\")\n",
    "    print(f\"   pip install git+https://github.com/experimentech/Pushing-Medium.git#subdirectory=programs/demos/machine_learning/nn_lib_v2\")\n",
    "\n",
    "else:\n",
    "    print(f\"â³ PMFlow BNN configuration pending library availability\")\n",
    "    print(f\"\\nğŸš€ TO USE THIS NOTEBOOK:\")\n",
    "    print(f\"   1. Ensure PMFlow BNN v0.2.0 is pushed to GitHub\")\n",
    "    print(f\"   2. Run: pip install git+https://github.com/experimentech/Pushing-Medium.git#subdirectory=programs/demos/machine_learning/nn_lib_v2\")\n",
    "    print(f\"   3. Restart notebook and re-run cells\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa57f3a",
   "metadata": {},
   "source": [
    "# âš¡ Performance Monitoring & Resource Utilization\n",
    "\n",
    "Real-time monitoring of CPU cores, GPU cores, and system resources during PMFlow execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd499cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Monitoring and Resource Utilization\n",
    "import threading\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SystemMonitor:\n",
    "    \"\"\"Real-time system resource monitoring during PMFlow execution.\"\"\"\n",
    "    \n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.monitoring = False\n",
    "        self.data = defaultdict(list)\n",
    "        self.timestamps = []\n",
    "        \n",
    "    def start_monitoring(self):\n",
    "        \"\"\"Start background monitoring thread.\"\"\"\n",
    "        if self.monitoring:\n",
    "            return\n",
    "            \n",
    "        self.monitoring = True\n",
    "        self.data.clear()\n",
    "        self.timestamps.clear()\n",
    "        \n",
    "        def monitor_loop():\n",
    "            start_time = time.time()\n",
    "            \n",
    "            while self.monitoring:\n",
    "                current_time = time.time() - start_time\n",
    "                self.timestamps.append(current_time)\n",
    "                \n",
    "                # CPU monitoring\n",
    "                cpu_percent = psutil.cpu_percent(interval=None, percpu=True)\n",
    "                self.data['cpu_total'].append(psutil.cpu_percent(interval=None))\n",
    "                for i, percent in enumerate(cpu_percent):\n",
    "                    self.data[f'cpu_core_{i}'].append(percent)\n",
    "                \n",
    "                # Memory monitoring\n",
    "                memory = psutil.virtual_memory()\n",
    "                self.data['memory_used_gb'].append(memory.used / (1024**3))\n",
    "                self.data['memory_percent'].append(memory.percent)\n",
    "                \n",
    "                # GPU monitoring (if available)\n",
    "                if self.device.type == 'cuda':\n",
    "                    try:\n",
    "                        # GPU memory\n",
    "                        gpu_memory_allocated = torch.cuda.memory_allocated(self.device) / (1024**3)\n",
    "                        gpu_memory_reserved = torch.cuda.memory_reserved(self.device) / (1024**3)\n",
    "                        self.data['gpu_memory_allocated_gb'].append(gpu_memory_allocated)\n",
    "                        self.data['gpu_memory_reserved_gb'].append(gpu_memory_reserved)\n",
    "                        \n",
    "                        # GPU utilization (approximate via memory usage)\n",
    "                        total_gpu_memory = torch.cuda.get_device_properties(self.device).total_memory / (1024**3)\n",
    "                        gpu_utilization = (gpu_memory_allocated / total_gpu_memory) * 100\n",
    "                        self.data['gpu_utilization_percent'].append(gpu_utilization)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        self.data['gpu_memory_allocated_gb'].append(0)\n",
    "                        self.data['gpu_memory_reserved_gb'].append(0)\n",
    "                        self.data['gpu_utilization_percent'].append(0)\n",
    "                \n",
    "                time.sleep(0.1)  # Monitor every 100ms\n",
    "        \n",
    "        self.monitor_thread = threading.Thread(target=monitor_loop, daemon=True)\n",
    "        self.monitor_thread.start()\n",
    "        \n",
    "    def stop_monitoring(self):\n",
    "        \"\"\"Stop monitoring and return collected data.\"\"\"\n",
    "        self.monitoring = False\n",
    "        if hasattr(self, 'monitor_thread'):\n",
    "            self.monitor_thread.join(timeout=1.0)\n",
    "        \n",
    "        return dict(self.data), self.timestamps.copy()\n",
    "    \n",
    "    def get_summary_stats(self):\n",
    "        \"\"\"Get summary statistics from monitoring data.\"\"\"\n",
    "        if not self.data:\n",
    "            return {}\n",
    "        \n",
    "        stats = {}\n",
    "        \n",
    "        # CPU stats\n",
    "        if 'cpu_total' in self.data:\n",
    "            stats['cpu_avg_percent'] = np.mean(self.data['cpu_total'])\n",
    "            stats['cpu_max_percent'] = np.max(self.data['cpu_total'])\n",
    "            stats['cpu_cores_used'] = sum(1 for core in range(system_capabilities['cpu']['cpu_count_logical']) \n",
    "                                         if f'cpu_core_{core}' in self.data and \n",
    "                                         np.mean(self.data[f'cpu_core_{core}']) > 5.0)\n",
    "        \n",
    "        # Memory stats\n",
    "        if 'memory_percent' in self.data:\n",
    "            stats['memory_avg_percent'] = np.mean(self.data['memory_percent'])\n",
    "            stats['memory_max_gb'] = np.max(self.data['memory_used_gb'])\n",
    "        \n",
    "        # GPU stats\n",
    "        if 'gpu_utilization_percent' in self.data:\n",
    "            stats['gpu_avg_percent'] = np.mean(self.data['gpu_utilization_percent'])\n",
    "            stats['gpu_max_memory_gb'] = np.max(self.data['gpu_memory_allocated_gb'])\n",
    "        \n",
    "        return stats\n",
    "\n",
    "def create_utilization_plots(monitor_data, timestamps, title=\"Resource Utilization\"):\n",
    "    \"\"\"Create comprehensive resource utilization plots.\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(f'{title} - Real-time Resource Monitoring', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # CPU utilization\n",
    "    ax1 = axes[0, 0]\n",
    "    if 'cpu_total' in monitor_data:\n",
    "        ax1.plot(timestamps, monitor_data['cpu_total'], 'b-', linewidth=2, label='Total CPU')\n",
    "        \n",
    "        # Plot individual cores (up to 8 for readability)\n",
    "        colors = plt.cm.Set3(np.linspace(0, 1, min(8, system_capabilities['cpu']['cpu_count_logical'])))\n",
    "        for i in range(min(8, system_capabilities['cpu']['cpu_count_logical'])):\n",
    "            if f'cpu_core_{i}' in monitor_data:\n",
    "                ax1.plot(timestamps, monitor_data[f'cpu_core_{i}'], \n",
    "                        color=colors[i], alpha=0.7, linewidth=1, label=f'Core {i}')\n",
    "    \n",
    "    ax1.set_xlabel('Time (seconds)')\n",
    "    ax1.set_ylabel('CPU Usage (%)')\n",
    "    ax1.set_title('CPU Core Utilization')\n",
    "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(0, 100)\n",
    "    \n",
    "    # Memory utilization\n",
    "    ax2 = axes[0, 1]\n",
    "    if 'memory_percent' in monitor_data:\n",
    "        ax2.plot(timestamps, monitor_data['memory_percent'], 'g-', linewidth=2, label='Memory %')\n",
    "        ax2_gb = ax2.twinx()\n",
    "        ax2_gb.plot(timestamps, monitor_data['memory_used_gb'], 'g--', linewidth=2, alpha=0.7, label='Memory GB')\n",
    "        ax2_gb.set_ylabel('Memory Usage (GB)', color='g')\n",
    "    \n",
    "    ax2.set_xlabel('Time (seconds)')\n",
    "    ax2.set_ylabel('Memory Usage (%)', color='g')\n",
    "    ax2.set_title('Memory Utilization')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(0, 100)\n",
    "    \n",
    "    # GPU utilization\n",
    "    ax3 = axes[1, 0]\n",
    "    if 'gpu_utilization_percent' in monitor_data and any(monitor_data['gpu_utilization_percent']):\n",
    "        ax3.plot(timestamps, monitor_data['gpu_utilization_percent'], 'r-', linewidth=2, label='GPU Utilization')\n",
    "        ax3_mem = ax3.twinx()\n",
    "        ax3_mem.plot(timestamps, monitor_data['gpu_memory_allocated_gb'], 'r--', linewidth=2, alpha=0.7, label='GPU Memory')\n",
    "        ax3_mem.set_ylabel('GPU Memory (GB)', color='r')\n",
    "        ax3.set_ylabel('GPU Utilization (%)', color='r')\n",
    "        ax3.set_title('GPU Utilization')\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, 'No GPU Data Available', transform=ax3.transAxes, \n",
    "                ha='center', va='center', fontsize=12)\n",
    "        ax3.set_title('GPU Utilization (N/A)')\n",
    "    \n",
    "    ax3.set_xlabel('Time (seconds)')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Summary statistics\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Calculate and display summary stats\n",
    "    summary_text = \"ğŸ“Š UTILIZATION SUMMARY:\\n\\n\"\n",
    "    \n",
    "    if 'cpu_total' in monitor_data:\n",
    "        cpu_avg = np.mean(monitor_data['cpu_total'])\n",
    "        cpu_max = np.max(monitor_data['cpu_total'])\n",
    "        summary_text += f\"ğŸ–¥ï¸  CPU:\\n\"\n",
    "        summary_text += f\"   Average: {cpu_avg:.1f}%\\n\"\n",
    "        summary_text += f\"   Peak: {cpu_max:.1f}%\\n\"\n",
    "        \n",
    "        # Count active cores\n",
    "        active_cores = sum(1 for i in range(system_capabilities['cpu']['cpu_count_logical'])\n",
    "                          if f'cpu_core_{i}' in monitor_data and \n",
    "                          np.mean(monitor_data[f'cpu_core_{i}']) > 5.0)\n",
    "        summary_text += f\"   Active Cores: {active_cores}/{system_capabilities['cpu']['cpu_count_logical']}\\n\\n\"\n",
    "    \n",
    "    if 'memory_percent' in monitor_data:\n",
    "        mem_avg = np.mean(monitor_data['memory_percent'])\n",
    "        mem_max_gb = np.max(monitor_data['memory_used_gb'])\n",
    "        summary_text += f\"ğŸ’¾ Memory:\\n\"\n",
    "        summary_text += f\"   Average: {mem_avg:.1f}%\\n\"\n",
    "        summary_text += f\"   Peak Usage: {mem_max_gb:.1f} GB\\n\\n\"\n",
    "    \n",
    "    if 'gpu_utilization_percent' in monitor_data and any(monitor_data['gpu_utilization_percent']):\n",
    "        gpu_avg = np.mean(monitor_data['gpu_utilization_percent'])\n",
    "        gpu_max_mem = np.max(monitor_data['gpu_memory_allocated_gb'])\n",
    "        summary_text += f\"ğŸ® GPU:\\n\"\n",
    "        summary_text += f\"   Average: {gpu_avg:.1f}%\\n\"\n",
    "        summary_text += f\"   Peak Memory: {gpu_max_mem:.1f} GB\\n\"\n",
    "    else:\n",
    "        summary_text += f\"ğŸ® GPU: Not Available\\n\"\n",
    "    \n",
    "    ax4.text(0.1, 0.9, summary_text, transform=ax4.transAxes, fontsize=10, \n",
    "            verticalalignment='top', fontfamily='monospace')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Initialize system monitor\n",
    "monitor = SystemMonitor(device)\n",
    "print(\"âœ… System monitor initialized\")\n",
    "print(f\"   Monitoring device: {device}\")\n",
    "print(f\"   CPU cores available: {system_capabilities['cpu']['cpu_count_logical']}\")\n",
    "if system_capabilities['gpu']['cuda_available']:\n",
    "    print(f\"   GPU memory available: {system_capabilities['gpu']['gpu_memory_gb'][0]:.1f} GB\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Ready for performance monitoring during PMFlow execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb38470",
   "metadata": {},
   "source": [
    "# ğŸ§ª Comprehensive Feature Testing\n",
    "\n",
    "Test all PMFlow BNN features with detailed metrics collection for multi-system comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55d9486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Feature Testing\n",
    "def run_comprehensive_pmflow_tests():\n",
    "    \"\"\"Run all PMFlow BNN tests with detailed metrics collection.\"\"\"\n",
    "    \n",
    "    if not library_available:\n",
    "        print(\"âŒ PMFlow BNN library not available - skipping tests\")\n",
    "        print(\"ğŸ“ Run this notebook after library is available locally or from GitHub\")\n",
    "        return None\n",
    "    \n",
    "    print(\"ğŸ§ª Starting Comprehensive PMFlow BNN Testing\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Test results storage\n",
    "    test_results = {\n",
    "        'system_info': system_capabilities,\n",
    "        'hardware_profile': hardware_profile,\n",
    "        'config': pmflow_config,\n",
    "        'tests': {}\n",
    "    }\n",
    "    \n",
    "    # Initialize evaluator\n",
    "    evaluator = PMFlowEvaluator(device=device)\n",
    "    \n",
    "    # Test 1: Model Creation and Basic Functionality\n",
    "    print(f\"\\nğŸ—ï¸  Test 1: Model Creation and Basic Functionality\")\n",
    "    try:\n",
    "        monitor.start_monitoring()\n",
    "        \n",
    "        model = get_model_v2(**pmflow_config).to(device)\n",
    "        param_count = sum(p.numel() for p in model.parameters())\n",
    "        \n",
    "        # Test forward pass\n",
    "        test_input = torch.randn(8, 28*28, device=device)\n",
    "        with torch.no_grad():\n",
    "            output = model(test_input)\n",
    "            if isinstance(output, tuple):\n",
    "                logits, hidden = output\n",
    "            else:\n",
    "                logits = output\n",
    "        \n",
    "        monitor_data, timestamps = monitor.stop_monitoring()\n",
    "        \n",
    "        test_results['tests']['model_creation'] = {\n",
    "            'status': 'success',\n",
    "            'param_count': param_count,\n",
    "            'output_shape': list(logits.shape),\n",
    "            'monitor_data': monitor_data,\n",
    "            'timestamps': timestamps\n",
    "        }\n",
    "        \n",
    "        print(f\"   âœ… Model created: {param_count:,} parameters\")\n",
    "        print(f\"   âœ… Forward pass: {test_input.shape} â†’ {logits.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        monitor.stop_monitoring()\n",
    "        test_results['tests']['model_creation'] = {\n",
    "            'status': 'failed',\n",
    "            'error': str(e)\n",
    "        }\n",
    "        print(f\"   âŒ Model creation failed: {e}\")\n",
    "        return test_results\n",
    "    \n",
    "    # Test 2: Embarrassingly Parallel Scaling\n",
    "    print(f\"\\nğŸš€ Test 2: Embarrassingly Parallel Scaling\")\n",
    "    try:\n",
    "        monitor.start_monitoring()\n",
    "        \n",
    "        max_batch = 32 if device.type == 'cuda' else 16\n",
    "        scaling_results = evaluator.evaluate_embarrassingly_parallel_scaling(\n",
    "            model, max_batch_size=max_batch, input_shape=(28*28,)\n",
    "        )\n",
    "        \n",
    "        monitor_data, timestamps = monitor.stop_monitoring()\n",
    "        \n",
    "        test_results['tests']['embarrassingly_parallel'] = {\n",
    "            'status': 'success',\n",
    "            'results': scaling_results,\n",
    "            'monitor_data': monitor_data,\n",
    "            'timestamps': timestamps\n",
    "        }\n",
    "        \n",
    "        print(f\"   âœ… Peak efficiency: {scaling_results['peak_efficiency']:.2f}x\")\n",
    "        print(f\"   âœ… Average efficiency: {scaling_results['average_efficiency']:.2f}x\")\n",
    "        print(f\"   âœ… Embarrassingly parallel: {scaling_results['is_embarrassingly_parallel']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        monitor.stop_monitoring()\n",
    "        test_results['tests']['embarrassingly_parallel'] = {\n",
    "            'status': 'failed', \n",
    "            'error': str(e)\n",
    "        }\n",
    "        print(f\"   âŒ Scaling test failed: {e}\")\n",
    "    \n",
    "    # Test 3: Gravitational Center Dynamics\n",
    "    print(f\"\\nğŸŒŒ Test 3: Gravitational Center Dynamics\")\n",
    "    try:\n",
    "        monitor.start_monitoring()\n",
    "        \n",
    "        # Generate test data\n",
    "        test_data = torch.randn(100, 28*28)\n",
    "        test_labels = torch.randint(0, 4, (100,))\n",
    "        \n",
    "        dynamics_results = evaluator.evaluate_gravitational_dynamics(\n",
    "            model, test_data, test_labels, adaptation_steps=10\n",
    "        )\n",
    "        \n",
    "        monitor_data, timestamps = monitor.stop_monitoring()\n",
    "        \n",
    "        test_results['tests']['gravitational_dynamics'] = {\n",
    "            'status': 'success',\n",
    "            'results': dynamics_results,\n",
    "            'monitor_data': monitor_data,\n",
    "            'timestamps': timestamps\n",
    "        }\n",
    "        \n",
    "        if dynamics_results:\n",
    "            print(f\"   âœ… Center movement: {dynamics_results['mean_movement']:.4f}\")\n",
    "            if 'specialization_ratio' in dynamics_results:\n",
    "                print(f\"   âœ… Specialization ratio: {dynamics_results['specialization_ratio']:.2f}x\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸ No gravitational centers detected\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        monitor.stop_monitoring()\n",
    "        test_results['tests']['gravitational_dynamics'] = {\n",
    "            'status': 'failed',\n",
    "            'error': str(e)\n",
    "        }\n",
    "        print(f\"   âŒ Gravitational dynamics test failed: {e}\")\n",
    "    \n",
    "    # Test 4: Biological Plasticity\n",
    "    print(f\"\\nğŸ§  Test 4: Biological Plasticity\")\n",
    "    try:\n",
    "        monitor.start_monitoring()\n",
    "        \n",
    "        # Create shifting datasets for plasticity testing\n",
    "        train_data = torch.randn(200, 28*28) * 0.8\n",
    "        train_labels = torch.randint(0, 4, (200,))\n",
    "        \n",
    "        shifting_datasets = []\n",
    "        for i in range(3):\n",
    "            shift_data = torch.randn(100, 28*28) * (0.8 + i * 0.1)\n",
    "            shift_labels = torch.randint(0, 4, (100,))\n",
    "            shifting_datasets.append((shift_data, shift_labels))\n",
    "        \n",
    "        plasticity_results = evaluator.evaluate_biological_plasticity(\n",
    "            model, train_data, train_labels, shifting_datasets\n",
    "        )\n",
    "        \n",
    "        monitor_data, timestamps = monitor.stop_monitoring()\n",
    "        \n",
    "        test_results['tests']['biological_plasticity'] = {\n",
    "            'status': 'success',\n",
    "            'results': plasticity_results,\n",
    "            'monitor_data': monitor_data,\n",
    "            'timestamps': timestamps\n",
    "        }\n",
    "        \n",
    "        print(f\"   âœ… Plasticity score: {plasticity_results['plasticity_score']:.3f}\")\n",
    "        print(f\"   âœ… Memory retention: {plasticity_results['memory_retention']:.3f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        monitor.stop_monitoring()\n",
    "        test_results['tests']['biological_plasticity'] = {\n",
    "            'status': 'failed',\n",
    "            'error': str(e)\n",
    "        }\n",
    "        print(f\"   âŒ Plasticity test failed: {e}\")\n",
    "    \n",
    "    # Test 5: Performance Benchmarking\n",
    "    print(f\"\\nâš¡ Test 5: Performance Benchmarking\")\n",
    "    try:\n",
    "        monitor.start_monitoring()\n",
    "        \n",
    "        benchmark_batch_sizes = [4, 8, 16] if device.type == 'cpu' else [8, 16, 32, 64]\n",
    "        \n",
    "        benchmark_results = benchmark_temporal_parallelism(\n",
    "            model, batch_sizes=benchmark_batch_sizes, device=device, num_trials=5\n",
    "        )\n",
    "        \n",
    "        monitor_data, timestamps = monitor.stop_monitoring()\n",
    "        \n",
    "        test_results['tests']['performance_benchmark'] = {\n",
    "            'status': 'success',\n",
    "            'results': benchmark_results,\n",
    "            'monitor_data': monitor_data,\n",
    "            'timestamps': timestamps\n",
    "        }\n",
    "        \n",
    "        print(f\"   âœ… Benchmark completed for {len(benchmark_batch_sizes)} batch sizes\")\n",
    "        print(f\"   âœ… Throughput range: {min(benchmark_results['throughput']):.1f} - {max(benchmark_results['throughput']):.1f} samples/sec\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        monitor.stop_monitoring()\n",
    "        test_results['tests']['performance_benchmark'] = {\n",
    "            'status': 'failed',\n",
    "            'error': str(e)\n",
    "        }\n",
    "        print(f\"   âŒ Benchmark failed: {e}\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ Comprehensive testing complete!\")\n",
    "    return test_results\n",
    "\n",
    "# Run tests if library is available\n",
    "if library_available:\n",
    "    test_results = run_comprehensive_pmflow_tests()\n",
    "else:\n",
    "    print(\"â³ Comprehensive testing pending library availability\")\n",
    "    print(\"ğŸ“ This cell will run automatically once the library is imported\")\n",
    "    test_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6e3f8f",
   "metadata": {},
   "source": [
    "# ğŸ“Š Results Analysis and Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e27737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results Analysis and Reporting\n",
    "def analyze_test_results(test_results):\n",
    "    \"\"\"Analyze and visualize comprehensive test results.\"\"\"\n",
    "    \n",
    "    if test_results is None:\n",
    "        print(\"ğŸ“ No test results available - run comprehensive tests first\")\n",
    "        return\n",
    "    \n",
    "    print(\"ğŸ“Š PMFlow BNN v0.2.0 Library Test Results\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # System Summary\n",
    "    print(f\"\\nğŸ–¥ï¸  System Configuration:\")\n",
    "    sys_info = test_results['system_info']\n",
    "    print(f\"   Platform: {sys_info['system']['platform']}\")\n",
    "    print(f\"   CPU Cores: {sys_info['cpu']['cpu_count_logical']} logical, {sys_info['cpu']['cpu_count_physical']} physical\")\n",
    "    print(f\"   Memory: {sys_info['memory']['total_ram_gb']:.1f} GB\")\n",
    "    if sys_info['gpu']['cuda_available']:\n",
    "        print(f\"   GPU: {sys_info['gpu']['gpu_names'][0]} ({sys_info['gpu']['gpu_memory_gb'][0]:.1f} GB)\")\n",
    "    else:\n",
    "        print(f\"   GPU: None (CPU only)\")\n",
    "    print(f\"   Profile: {test_results['hardware_profile']}\")\n",
    "    \n",
    "    # Test Summary\n",
    "    tests = test_results['tests']\n",
    "    passed_tests = sum(1 for test in tests.values() if test['status'] == 'success')\n",
    "    total_tests = len(tests)\n",
    "    success_rate = (passed_tests / total_tests) * 100 if total_tests > 0 else 0\n",
    "    \n",
    "    print(f\"\\nâœ… Test Summary:\")\n",
    "    print(f\"   Passed: {passed_tests}/{total_tests} ({success_rate:.1f}%)\")\n",
    "    \n",
    "    # Individual Test Results\n",
    "    for test_name, test_data in tests.items():\n",
    "        status_icon = \"âœ…\" if test_data['status'] == 'success' else \"âŒ\"\n",
    "        print(f\"   {status_icon} {test_name.replace('_', ' ').title()}\")\n",
    "        \n",
    "        if test_data['status'] == 'failed':\n",
    "            print(f\"      Error: {test_data['error']}\")\n",
    "    \n",
    "    # Performance Analysis\n",
    "    print(f\"\\nâš¡ Performance Analysis:\")\n",
    "    \n",
    "    # Embarrassingly Parallel Results\n",
    "    if 'embarrassingly_parallel' in tests and tests['embarrassingly_parallel']['status'] == 'success':\n",
    "        ep_results = tests['embarrassingly_parallel']['results']\n",
    "        print(f\"   ğŸš€ Embarrassingly Parallel Scaling:\")\n",
    "        print(f\"      Peak Efficiency: {ep_results['peak_efficiency']:.2f}x\")\n",
    "        print(f\"      Average Efficiency: {ep_results['average_efficiency']:.2f}x\")\n",
    "        print(f\"      Is Embarrassingly Parallel: {ep_results['is_embarrassingly_parallel']}\")\n",
    "    \n",
    "    # Gravitational Dynamics\n",
    "    if 'gravitational_dynamics' in tests and tests['gravitational_dynamics']['status'] == 'success':\n",
    "        gd_results = tests['gravitational_dynamics']['results']\n",
    "        if gd_results:\n",
    "            print(f\"   ğŸŒŒ Gravitational Dynamics:\")\n",
    "            print(f\"      Mean Center Movement: {gd_results['mean_movement']:.4f}\")\n",
    "            if 'specialization_ratio' in gd_results:\n",
    "                print(f\"      Specialization Ratio: {gd_results['specialization_ratio']:.2f}x\")\n",
    "    \n",
    "    # Biological Plasticity\n",
    "    if 'biological_plasticity' in tests and tests['biological_plasticity']['status'] == 'success':\n",
    "        bp_results = tests['biological_plasticity']['results']\n",
    "        print(f\"   ğŸ§  Biological Plasticity:\")\n",
    "        print(f\"      Plasticity Score: {bp_results['plasticity_score']:.3f}\")\n",
    "        print(f\"      Memory Retention: {bp_results['memory_retention']:.3f}\")\n",
    "    \n",
    "    # Resource Utilization Summary\n",
    "    print(f\"\\nğŸ”§ Resource Utilization:\")\n",
    "    for test_name, test_data in tests.items():\n",
    "        if test_data['status'] == 'success' and 'monitor_data' in test_data:\n",
    "            monitor_data = test_data['monitor_data']\n",
    "            if monitor_data and 'cpu_total' in monitor_data and 'memory_percent' in monitor_data:\n",
    "                avg_cpu = sum(monitor_data['cpu_total']) / len(monitor_data['cpu_total'])\n",
    "                avg_memory = sum(monitor_data['memory_percent']) / len(monitor_data['memory_percent'])\n",
    "                print(f\"   {test_name.replace('_', ' ').title()}:\")\n",
    "                print(f\"      CPU: {avg_cpu:.1f}% | Memory: {avg_memory:.1f}%\")\n",
    "                \n",
    "                if 'gpu_utilization_percent' in monitor_data and any(monitor_data['gpu_utilization_percent']):\n",
    "                    avg_gpu = sum(monitor_data['gpu_utilization_percent']) / len(monitor_data['gpu_utilization_percent'])\n",
    "                    avg_gpu_mem = sum(monitor_data['gpu_memory_allocated_gb']) / len(monitor_data['gpu_memory_allocated_gb'])\n",
    "                    print(f\"      GPU: {avg_gpu:.1f}% | GPU Memory: {avg_gpu_mem:.1f} GB\")\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "def visualize_performance_data(test_results):\n",
    "    \"\"\"Create performance visualizations.\"\"\"\n",
    "    \n",
    "    if test_results is None or not any(t['status'] == 'success' for t in test_results['tests'].values()):\n",
    "        print(\"ğŸ“Š No successful test data available for visualization\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle('PMFlow BNN v0.2.0 Performance Analysis', fontsize=16)\n",
    "        \n",
    "        # 1. Embarrassingly Parallel Scaling\n",
    "        if ('embarrassingly_parallel' in test_results['tests'] and \n",
    "            test_results['tests']['embarrassingly_parallel']['status'] == 'success'):\n",
    "            \n",
    "            ep_results = test_results['tests']['embarrassingly_parallel']['results']\n",
    "            batch_sizes = ep_results['batch_sizes']\n",
    "            scaling_efficiency = ep_results['scaling_efficiency']\n",
    "            \n",
    "            axes[0,0].plot(batch_sizes, scaling_efficiency, 'b-o', linewidth=2, markersize=6)\n",
    "            axes[0,0].axhline(y=1.0, color='r', linestyle='--', alpha=0.7, label='Perfect Linear')\n",
    "            axes[0,0].set_xlabel('Batch Size')\n",
    "            axes[0,0].set_ylabel('Scaling Efficiency')\n",
    "            axes[0,0].set_title('Embarrassingly Parallel Scaling')\n",
    "            axes[0,0].grid(True, alpha=0.3)\n",
    "            axes[0,0].legend()\n",
    "            axes[0,0].set_ylim(0, max(scaling_efficiency) * 1.1)\n",
    "        else:\n",
    "            axes[0,0].text(0.5, 0.5, 'No Scaling Data Available', transform=axes[0,0].transAxes, \n",
    "                          ha='center', va='center', fontsize=12)\n",
    "            axes[0,0].set_title('Embarrassingly Parallel Scaling (N/A)')\n",
    "        \n",
    "        # 2. Resource Utilization Across Tests\n",
    "        test_names = []\n",
    "        cpu_usage = []\n",
    "        memory_usage = []\n",
    "        \n",
    "        for test_name, test_data in test_results['tests'].items():\n",
    "            if test_data['status'] == 'success' and 'monitor_data' in test_data:\n",
    "                monitor_data = test_data['monitor_data']\n",
    "                if monitor_data and 'cpu_total' in monitor_data and 'memory_percent' in monitor_data:\n",
    "                    test_names.append(test_name.replace('_', ' ').title())\n",
    "                    cpu_usage.append(sum(monitor_data['cpu_total']) / len(monitor_data['cpu_total']))\n",
    "                    memory_usage.append(sum(monitor_data['memory_percent']) / len(monitor_data['memory_percent']))\n",
    "        \n",
    "        if test_names:\n",
    "            x_pos = range(len(test_names))\n",
    "            axes[0,1].bar([p - 0.2 for p in x_pos], cpu_usage, 0.4, label='CPU %', alpha=0.8)\n",
    "            axes[0,1].bar([p + 0.2 for p in x_pos], memory_usage, 0.4, label='Memory %', alpha=0.8)\n",
    "            axes[0,1].set_xlabel('Test')\n",
    "            axes[0,1].set_ylabel('Usage %')\n",
    "            axes[0,1].set_title('Resource Utilization by Test')\n",
    "            axes[0,1].set_xticks(x_pos)\n",
    "            axes[0,1].set_xticklabels(test_names, rotation=45, ha='right')\n",
    "            axes[0,1].legend()\n",
    "            axes[0,1].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[0,1].text(0.5, 0.5, 'No Resource Data Available', transform=axes[0,1].transAxes, \n",
    "                          ha='center', va='center', fontsize=12)\n",
    "            axes[0,1].set_title('Resource Utilization (N/A)')\n",
    "        \n",
    "        # 3. Performance Benchmark\n",
    "        if ('performance_benchmark' in test_results['tests'] and \n",
    "            test_results['tests']['performance_benchmark']['status'] == 'success'):\n",
    "            \n",
    "            bench_results = test_results['tests']['performance_benchmark']['results']\n",
    "            batch_sizes = bench_results['batch_sizes']\n",
    "            throughput = bench_results['throughput']\n",
    "            \n",
    "            axes[1,0].plot(batch_sizes, throughput, 'g-s', linewidth=2, markersize=6)\n",
    "            axes[1,0].set_xlabel('Batch Size')\n",
    "            axes[1,0].set_ylabel('Throughput (samples/sec)')\n",
    "            axes[1,0].set_title('Performance Throughput')\n",
    "            axes[1,0].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[1,0].text(0.5, 0.5, 'No Benchmark Data Available', transform=axes[1,0].transAxes, \n",
    "                          ha='center', va='center', fontsize=12)\n",
    "            axes[1,0].set_title('Performance Throughput (N/A)')\n",
    "        \n",
    "        # 4. Test Success Summary\n",
    "        test_statuses = [test['status'] for test in test_results['tests'].values()]\n",
    "        success_count = test_statuses.count('success')\n",
    "        failure_count = test_statuses.count('failed')\n",
    "        \n",
    "        if success_count + failure_count > 0:\n",
    "            labels = ['Passed', 'Failed']\n",
    "            sizes = [success_count, failure_count]\n",
    "            colors = ['#2ecc71', '#e74c3c']\n",
    "            \n",
    "            # Only show pie chart if there are any failures, otherwise show success message\n",
    "            if failure_count > 0:\n",
    "                axes[1,1].pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "            else:\n",
    "                axes[1,1].pie([1], labels=['All Tests Passed'], colors=['#2ecc71'], autopct='100.0%%', startangle=90)\n",
    "            axes[1,1].set_title(f'Test Success Rate ({success_count}/{success_count+failure_count})')\n",
    "        else:\n",
    "            axes[1,1].text(0.5, 0.5, 'No Test Data Available', transform=axes[1,1].transAxes, \n",
    "                          ha='center', va='center', fontsize=12)\n",
    "            axes[1,1].set_title('Test Success Rate (N/A)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"ğŸ“Š Performance visualizations generated successfully\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"ğŸ“Š Matplotlib not available - install for visualizations\")\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸ“Š Visualization error: {e}\")\n",
    "\n",
    "def generate_deployment_report(test_results):\n",
    "    \"\"\"Generate deployment readiness report.\"\"\"\n",
    "    \n",
    "    if test_results is None:\n",
    "        print(\"ğŸ“ No test results available for deployment report\")\n",
    "        return\n",
    "    \n",
    "    print(\"ğŸš€ PMFlow BNN v0.2.0 Deployment Readiness Report\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    tests = test_results['tests']\n",
    "    passed_tests = sum(1 for test in tests.values() if test['status'] == 'success')\n",
    "    total_tests = len(tests)\n",
    "    success_rate = (passed_tests / total_tests) * 100 if total_tests > 0 else 0\n",
    "    \n",
    "    # Deployment readiness assessment\n",
    "    critical_tests = ['model_creation', 'embarrassingly_parallel']\n",
    "    critical_passed = sum(1 for test in critical_tests if test in tests and tests[test]['status'] == 'success')\n",
    "    \n",
    "    deployment_ready = (success_rate >= 80.0 and critical_passed == len(critical_tests))\n",
    "    \n",
    "    print(f\"ğŸ“Š Overall Status: {'âœ… READY FOR DEPLOYMENT' if deployment_ready else 'âš ï¸ NEEDS ATTENTION'}\")\n",
    "    print(f\"ğŸ“ˆ Success Rate: {success_rate:.1f}% ({passed_tests}/{total_tests})\")\n",
    "    print(f\"ğŸ”§ Critical Tests: {critical_passed}/{len(critical_tests)} passed\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Next Steps:\")\n",
    "    if deployment_ready:\n",
    "        print(\"   1. âœ… Commit library to GitHub\")\n",
    "        print(\"   2. âœ… Test GitHub import functionality\") \n",
    "        print(\"   3. âœ… Deploy to Jetson Nano for edge testing\")\n",
    "        print(\"   4. âœ… Run cross-system performance validation\")\n",
    "    else:\n",
    "        print(\"   1. âŒ Fix failing tests before deployment\")\n",
    "        for test_name, test_data in tests.items():\n",
    "            if test_data['status'] == 'failed':\n",
    "                print(f\"      - {test_name}: {test_data['error']}\")\n",
    "        print(\"   2. âŒ Re-run comprehensive tests\")\n",
    "        print(\"   3. âŒ Achieve >80% success rate before GitHub deployment\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ Recommendations:\")\n",
    "    \n",
    "    # Performance recommendations\n",
    "    if 'embarrassingly_parallel' in tests and tests['embarrassingly_parallel']['status'] == 'success':\n",
    "        ep_results = tests['embarrassingly_parallel']['results']\n",
    "        if ep_results['peak_efficiency'] < 0.8:\n",
    "            print(f\"   âš¡ Consider optimizing parallel efficiency (current peak: {ep_results['peak_efficiency']:.2f}x)\")\n",
    "        else:\n",
    "            print(\"   âœ… Excellent parallel scaling achieved\")\n",
    "    \n",
    "    # Resource recommendations\n",
    "    system_info = test_results['system_info']\n",
    "    if system_info['cpu']['cpu_count_logical'] >= 4:\n",
    "        print(\"   ğŸ–¥ï¸ Multi-core system detected - optimal for PMFlow BNN\")\n",
    "    else:\n",
    "        print(\"   âš ï¸ Limited cores detected - consider CPU optimizations\")\n",
    "    \n",
    "    if system_info['gpu']['cuda_available']:\n",
    "        print(\"   ğŸ® GPU available - leverage for large-scale testing\")\n",
    "    else:\n",
    "        print(\"   ğŸ’» CPU-only system - focus on CPU optimizations\")\n",
    "    \n",
    "    return deployment_ready\n",
    "\n",
    "# Run analysis if test results are available\n",
    "if 'test_results' in locals() and test_results is not None:\n",
    "    print(\"ğŸ” Analyzing test results...\")\n",
    "    analyzed_results = analyze_test_results(test_results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    visualize_performance_data(test_results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    deployment_ready = generate_deployment_report(test_results)\n",
    "else:\n",
    "    print(\"â³ Results analysis pending comprehensive test completion\")\n",
    "    print(\"ğŸ“ This analysis will run automatically after comprehensive testing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
