{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15cd6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PMFlow BNN v0.2.0 Comprehensive Testing Notebook\n",
    "# ================================================\n",
    "# \n",
    "# This notebook thoroughly tests the PMFlow BNN v0.2.0 library with:\n",
    "# - Automatic hardware detection and configuration\n",
    "# - CPU core / GPU core utilization monitoring  \n",
    "# - Performance benchmarks for multi-system comparison\n",
    "# - Complete feature validation\n",
    "# - Detailed metrics collection\n",
    "\n",
    "print(\"üéØ PMFlow BNN v0.2.0 Comprehensive Testing Notebook\")\n",
    "print(\"=\"*55)\n",
    "print(\"Loading testing framework...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fde08e",
   "metadata": {},
   "source": [
    "# üñ•Ô∏è System Detection & Hardware Analysis\n",
    "\n",
    "This notebook automatically detects hardware capabilities and configures PMFlow BNN accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f89e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Detection and Hardware Analysis\n",
    "import sys\n",
    "import os\n",
    "import platform\n",
    "import psutil\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Any, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Advanced hardware detection\n",
    "def detect_system_capabilities():\n",
    "    \"\"\"Comprehensive system detection with CPU/GPU core counting.\"\"\"\n",
    "    \n",
    "    print(\"üîç Detecting System Capabilities...\")\n",
    "    \n",
    "    # Basic system info\n",
    "    system_info = {\n",
    "        'platform': platform.platform(),\n",
    "        'python_version': sys.version.split()[0],\n",
    "        'architecture': platform.architecture()[0],\n",
    "        'processor': platform.processor(),\n",
    "    }\n",
    "    \n",
    "    # CPU detection\n",
    "    cpu_info = {\n",
    "        'cpu_count_logical': psutil.cpu_count(logical=True),\n",
    "        'cpu_count_physical': psutil.cpu_count(logical=False),\n",
    "        'cpu_freq_max': psutil.cpu_freq().max if psutil.cpu_freq() else 'Unknown',\n",
    "        'cpu_freq_current': psutil.cpu_freq().current if psutil.cpu_freq() else 'Unknown',\n",
    "    }\n",
    "    \n",
    "    # Memory detection\n",
    "    memory = psutil.virtual_memory()\n",
    "    memory_info = {\n",
    "        'total_ram_gb': memory.total / (1024**3),\n",
    "        'available_ram_gb': memory.available / (1024**3),\n",
    "        'ram_usage_percent': memory.percent,\n",
    "    }\n",
    "    \n",
    "    # GPU detection\n",
    "    gpu_info = {\n",
    "        'cuda_available': torch.cuda.is_available(),\n",
    "        'gpu_count': torch.cuda.device_count() if torch.cuda.is_available() else 0,\n",
    "        'gpu_names': [],\n",
    "        'gpu_memory_gb': [],\n",
    "        'gpu_compute_capability': []\n",
    "    }\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            props = torch.cuda.get_device_properties(i)\n",
    "            gpu_info['gpu_names'].append(props.name)\n",
    "            gpu_info['gpu_memory_gb'].append(props.total_memory / (1024**3))\n",
    "            gpu_info['gpu_compute_capability'].append(f\"{props.major}.{props.minor}\")\n",
    "    \n",
    "    # Jetson detection\n",
    "    jetson_info = detect_jetson_nano()\n",
    "    \n",
    "    # Combine all info\n",
    "    capabilities = {\n",
    "        'system': system_info,\n",
    "        'cpu': cpu_info,\n",
    "        'memory': memory_info,\n",
    "        'gpu': gpu_info,\n",
    "        'jetson': jetson_info,\n",
    "    }\n",
    "    \n",
    "    return capabilities\n",
    "\n",
    "def detect_jetson_nano():\n",
    "    \"\"\"Detect if running on Jetson Nano with detailed specs.\"\"\"\n",
    "    jetson_info = {\n",
    "        'is_jetson': False,\n",
    "        'model': 'Unknown',\n",
    "        'tegra_version': 'Unknown',\n",
    "        'cuda_arch': 'Unknown'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Check device tree model\n",
    "        with open('/proc/device-tree/model', 'r') as f:\n",
    "            model = f.read().strip()\n",
    "            if 'jetson' in model.lower() or 'tegra' in model.lower():\n",
    "                jetson_info['is_jetson'] = True\n",
    "                jetson_info['model'] = model\n",
    "        \n",
    "        # Check Tegra version\n",
    "        if os.path.exists('/proc/device-tree/compatible'):\n",
    "            with open('/proc/device-tree/compatible', 'r') as f:\n",
    "                compatible = f.read()\n",
    "                if 'tegra210' in compatible:\n",
    "                    jetson_info['tegra_version'] = 'Tegra X1 (210)'\n",
    "                    jetson_info['cuda_arch'] = 'Maxwell (5.3)'\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return jetson_info\n",
    "\n",
    "def print_system_summary(capabilities):\n",
    "    \"\"\"Print formatted system summary.\"\"\"\n",
    "    \n",
    "    print(f\"\\nüìã SYSTEM SUMMARY:\")\n",
    "    print(f\"   Platform: {capabilities['system']['platform']}\")\n",
    "    print(f\"   Architecture: {capabilities['system']['architecture']}\")\n",
    "    print(f\"   Python: {capabilities['system']['python_version']}\")\n",
    "    \n",
    "    print(f\"\\nüñ•Ô∏è  CPU INFORMATION:\")\n",
    "    print(f\"   Logical Cores: {capabilities['cpu']['cpu_count_logical']}\")\n",
    "    print(f\"   Physical Cores: {capabilities['cpu']['cpu_count_physical']}\")\n",
    "    print(f\"   Max Frequency: {capabilities['cpu']['cpu_freq_max']} MHz\")\n",
    "    \n",
    "    print(f\"\\nüíæ MEMORY INFORMATION:\")\n",
    "    print(f\"   Total RAM: {capabilities['memory']['total_ram_gb']:.1f} GB\")\n",
    "    print(f\"   Available RAM: {capabilities['memory']['available_ram_gb']:.1f} GB\")\n",
    "    print(f\"   Usage: {capabilities['memory']['ram_usage_percent']:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nüéÆ GPU INFORMATION:\")\n",
    "    if capabilities['gpu']['cuda_available']:\n",
    "        print(f\"   CUDA Available: Yes\")\n",
    "        print(f\"   GPU Count: {capabilities['gpu']['gpu_count']}\")\n",
    "        for i, (name, memory, compute) in enumerate(zip(\n",
    "            capabilities['gpu']['gpu_names'],\n",
    "            capabilities['gpu']['gpu_memory_gb'],\n",
    "            capabilities['gpu']['gpu_compute_capability']\n",
    "        )):\n",
    "            print(f\"   GPU {i}: {name}\")\n",
    "            print(f\"     Memory: {memory:.1f} GB\")\n",
    "            print(f\"     Compute: {compute}\")\n",
    "    else:\n",
    "        print(f\"   CUDA Available: No\")\n",
    "    \n",
    "    if capabilities['jetson']['is_jetson']:\n",
    "        print(f\"\\nü§ñ JETSON INFORMATION:\")\n",
    "        print(f\"   Model: {capabilities['jetson']['model']}\")\n",
    "        print(f\"   Tegra: {capabilities['jetson']['tegra_version']}\")\n",
    "        print(f\"   CUDA Arch: {capabilities['jetson']['cuda_arch']}\")\n",
    "\n",
    "# Run system detection\n",
    "system_capabilities = detect_system_capabilities()\n",
    "print_system_summary(system_capabilities)\n",
    "\n",
    "# Determine optimal device\n",
    "if system_capabilities['gpu']['cuda_available']:\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"\\n‚úÖ Using GPU: {system_capabilities['gpu']['gpu_names'][0]}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(f\"\\n‚úÖ Using CPU: {system_capabilities['cpu']['cpu_count_logical']} logical cores\")\n",
    "\n",
    "print(f\"\\nüéØ System detection complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df13f46",
   "metadata": {},
   "source": [
    "# üìö Library Import & Configuration\n",
    "\n",
    "Import PMFlow BNN library and configure based on detected hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e319b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Import and Configuration\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Method 1: Try GitHub installation (preferred after library is pushed)\n",
    "print(\"üöÄ Attempting to install PMFlow BNN v0.2.0 from GitHub...\")\n",
    "print(\"üì¶ Installing: pip install git+https://github.com/experimentech/Pushing-Medium.git#subdirectory=programs/demos/machine_learning/nn_lib_v2\")\n",
    "\n",
    "try:\n",
    "    import subprocess\n",
    "    \n",
    "    # Install from GitHub - Python 3.6+ compatible subprocess call\n",
    "    result = subprocess.run([\n",
    "        sys.executable, '-m', 'pip', 'install', \n",
    "        'git+https://github.com/experimentech/Pushing-Medium.git#subdirectory=programs/demos/machine_learning/nn_lib_v2'\n",
    "    ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ Successfully installed PMFlow BNN v0.2.0 from GitHub!\")\n",
    "        installation_source = \"github\"\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è GitHub installation failed: {result.stderr}\")\n",
    "        print(\"üìÇ Falling back to local development path...\")\n",
    "        installation_source = \"local\"\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è GitHub installation error: {e}\")\n",
    "    print(\"üìÇ Falling back to local development path...\")\n",
    "    installation_source = \"local\"\n",
    "\n",
    "# Method 2: Local development fallback\n",
    "if installation_source == \"local\":\n",
    "    pmflow_library_path = '/home/tmumford/Documents/gravity/programs/demos/machine_learning/nn_lib_v2'\n",
    "    if os.path.exists(pmflow_library_path) and pmflow_library_path not in sys.path:\n",
    "        sys.path.insert(0, pmflow_library_path)\n",
    "        print(f\"üìÇ Added local library path: {pmflow_library_path}\")\n",
    "\n",
    "# Try to import PMFlow BNN\n",
    "try:\n",
    "    from pmflow_bnn import (\n",
    "        get_model_v2, \n",
    "        get_performance_config, \n",
    "        PMFlowEvaluator,\n",
    "        benchmark_temporal_parallelism,\n",
    "        validate_embarrassingly_parallel_scaling\n",
    "    )\n",
    "    print(\"‚úÖ PMFlow BNN library imported successfully\")\n",
    "    library_available = True\n",
    "    \n",
    "    # Get version info\n",
    "    try:\n",
    "        from pmflow_bnn.version import __version__\n",
    "        print(f\"üì¶ PMFlow BNN version: {__version__}\")\n",
    "    except:\n",
    "        print(\"üì¶ PMFlow BNN version: Development\")\n",
    "    \n",
    "    print(f\"üìç Installation source: {installation_source}\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå PMFlow BNN library not available: {e}\")\n",
    "    print(\"üìù Note: This notebook can run system detection but requires library for testing\")\n",
    "    library_available = False\n",
    "    installation_source = \"none\"\n",
    "\n",
    "# Configure based on detected hardware\n",
    "if library_available:\n",
    "    print(f\"\\nüîß Configuring PMFlow BNN for detected hardware...\")\n",
    "    \n",
    "    # Determine hardware profile\n",
    "    if system_capabilities['jetson']['is_jetson']:\n",
    "        hardware_profile = 'jetson_nano'\n",
    "        print(f\"   Hardware profile: Jetson Nano\")\n",
    "    elif system_capabilities['gpu']['gpu_count'] > 1:\n",
    "        hardware_profile = 'multi_gpu'\n",
    "        print(f\"   Hardware profile: Multi-GPU ({system_capabilities['gpu']['gpu_count']} GPUs)\")\n",
    "    elif system_capabilities['gpu']['cuda_available']:\n",
    "        hardware_profile = 'single_gpu'\n",
    "        print(f\"   Hardware profile: Single GPU\")\n",
    "    else:\n",
    "        hardware_profile = 'cpu'\n",
    "        print(f\"   Hardware profile: CPU ({system_capabilities['cpu']['cpu_count_logical']} cores)\")\n",
    "    \n",
    "    # Get optimized configuration\n",
    "    pmflow_config = get_performance_config(hardware_profile)\n",
    "    print(f\"   Model type: {pmflow_config['model_type']}\")\n",
    "    print(f\"   Centers: {pmflow_config['n_centers']}\")\n",
    "    print(f\"   PM steps: {pmflow_config['pm_steps']}\")\n",
    "    print(f\"   Temporal stages: {pmflow_config['temporal_stages']}\")\n",
    "    \n",
    "    print(f\"‚úÖ PMFlow BNN configured for optimal performance\")\n",
    "    \n",
    "    # Display installation instructions for other environments\n",
    "    print(f\"\\nüí° USAGE IN OTHER ENVIRONMENTS:\")\n",
    "    print(f\"   Google Colab:\")\n",
    "    print(f\"   !pip install git+https://github.com/experimentech/Pushing-Medium.git#subdirectory=programs/demos/machine_learning/nn_lib_v2\")\n",
    "    print(f\"   \")\n",
    "    print(f\"   Jetson Nano:\")\n",
    "    print(f\"   pip install git+https://github.com/experimentech/Pushing-Medium.git#subdirectory=programs/demos/machine_learning/nn_lib_v2\")\n",
    "    print(f\"   \")\n",
    "    print(f\"   Any Python environment:\")\n",
    "    print(f\"   pip install git+https://github.com/experimentech/Pushing-Medium.git#subdirectory=programs/demos/machine_learning/nn_lib_v2\")\n",
    "\n",
    "else:\n",
    "    print(f\"‚è≥ PMFlow BNN configuration pending library availability\")\n",
    "    print(f\"\\nüöÄ TO USE THIS NOTEBOOK:\")\n",
    "    print(f\"   1. Ensure PMFlow BNN v0.2.0 is pushed to GitHub\")\n",
    "    print(f\"   2. Run: pip install git+https://github.com/experimentech/Pushing-Medium.git#subdirectory=programs/demos/machine_learning/nn_lib_v2\")\n",
    "    print(f\"   3. Restart notebook and re-run cells\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa57f3a",
   "metadata": {},
   "source": [
    "# ‚ö° Performance Monitoring & Resource Utilization\n",
    "\n",
    "Real-time monitoring of CPU cores, GPU cores, and system resources during PMFlow execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd499cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Monitoring and Resource Utilization\n",
    "import threading\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SystemMonitor:\n",
    "    \"\"\"Real-time system resource monitoring during PMFlow execution.\"\"\"\n",
    "    \n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.monitoring = False\n",
    "        self.data = defaultdict(list)\n",
    "        self.timestamps = []\n",
    "        \n",
    "    def start_monitoring(self):\n",
    "        \"\"\"Start background monitoring thread.\"\"\"\n",
    "        if self.monitoring:\n",
    "            return\n",
    "            \n",
    "        self.monitoring = True\n",
    "        self.data.clear()\n",
    "        self.timestamps.clear()\n",
    "        \n",
    "        def monitor_loop():\n",
    "            start_time = time.time()\n",
    "            \n",
    "            while self.monitoring:\n",
    "                current_time = time.time() - start_time\n",
    "                self.timestamps.append(current_time)\n",
    "                \n",
    "                # CPU monitoring\n",
    "                cpu_percent = psutil.cpu_percent(interval=None, percpu=True)\n",
    "                self.data['cpu_total'].append(psutil.cpu_percent(interval=None))\n",
    "                for i, percent in enumerate(cpu_percent):\n",
    "                    self.data[f'cpu_core_{i}'].append(percent)\n",
    "                \n",
    "                # Memory monitoring\n",
    "                memory = psutil.virtual_memory()\n",
    "                self.data['memory_used_gb'].append(memory.used / (1024**3))\n",
    "                self.data['memory_percent'].append(memory.percent)\n",
    "                \n",
    "                # GPU monitoring (if available)\n",
    "                if self.device.type == 'cuda':\n",
    "                    try:\n",
    "                        # GPU memory\n",
    "                        gpu_memory_allocated = torch.cuda.memory_allocated(self.device) / (1024**3)\n",
    "                        gpu_memory_reserved = torch.cuda.memory_reserved(self.device) / (1024**3)\n",
    "                        self.data['gpu_memory_allocated_gb'].append(gpu_memory_allocated)\n",
    "                        self.data['gpu_memory_reserved_gb'].append(gpu_memory_reserved)\n",
    "                        \n",
    "                        # GPU utilization (approximate via memory usage)\n",
    "                        total_gpu_memory = torch.cuda.get_device_properties(self.device).total_memory / (1024**3)\n",
    "                        gpu_utilization = (gpu_memory_allocated / total_gpu_memory) * 100\n",
    "                        self.data['gpu_utilization_percent'].append(gpu_utilization)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        self.data['gpu_memory_allocated_gb'].append(0)\n",
    "                        self.data['gpu_memory_reserved_gb'].append(0)\n",
    "                        self.data['gpu_utilization_percent'].append(0)\n",
    "                \n",
    "                time.sleep(0.1)  # Monitor every 100ms\n",
    "        \n",
    "        self.monitor_thread = threading.Thread(target=monitor_loop, daemon=True)\n",
    "        self.monitor_thread.start()\n",
    "        \n",
    "    def stop_monitoring(self):\n",
    "        \"\"\"Stop monitoring and return collected data.\"\"\"\n",
    "        self.monitoring = False\n",
    "        if hasattr(self, 'monitor_thread'):\n",
    "            self.monitor_thread.join(timeout=1.0)\n",
    "        \n",
    "        return dict(self.data), self.timestamps.copy()\n",
    "    \n",
    "    def get_summary_stats(self):\n",
    "        \"\"\"Get summary statistics from monitoring data.\"\"\"\n",
    "        if not self.data:\n",
    "            return {}\n",
    "        \n",
    "        stats = {}\n",
    "        \n",
    "        # CPU stats\n",
    "        if 'cpu_total' in self.data:\n",
    "            stats['cpu_avg_percent'] = np.mean(self.data['cpu_total'])\n",
    "            stats['cpu_max_percent'] = np.max(self.data['cpu_total'])\n",
    "            stats['cpu_cores_used'] = sum(1 for core in range(system_capabilities['cpu']['cpu_count_logical']) \n",
    "                                         if f'cpu_core_{core}' in self.data and \n",
    "                                         np.mean(self.data[f'cpu_core_{core}']) > 5.0)\n",
    "        \n",
    "        # Memory stats\n",
    "        if 'memory_percent' in self.data:\n",
    "            stats['memory_avg_percent'] = np.mean(self.data['memory_percent'])\n",
    "            stats['memory_max_gb'] = np.max(self.data['memory_used_gb'])\n",
    "        \n",
    "        # GPU stats\n",
    "        if 'gpu_utilization_percent' in self.data:\n",
    "            stats['gpu_avg_percent'] = np.mean(self.data['gpu_utilization_percent'])\n",
    "            stats['gpu_max_memory_gb'] = np.max(self.data['gpu_memory_allocated_gb'])\n",
    "        \n",
    "        return stats\n",
    "\n",
    "def create_utilization_plots(monitor_data, timestamps, title=\"Resource Utilization\"):\n",
    "    \"\"\"Create comprehensive resource utilization plots.\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(f'{title} - Real-time Resource Monitoring', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # CPU utilization\n",
    "    ax1 = axes[0, 0]\n",
    "    if 'cpu_total' in monitor_data:\n",
    "        ax1.plot(timestamps, monitor_data['cpu_total'], 'b-', linewidth=2, label='Total CPU')\n",
    "        \n",
    "        # Plot individual cores (up to 8 for readability)\n",
    "        colors = plt.cm.Set3(np.linspace(0, 1, min(8, system_capabilities['cpu']['cpu_count_logical'])))\n",
    "        for i in range(min(8, system_capabilities['cpu']['cpu_count_logical'])):\n",
    "            if f'cpu_core_{i}' in monitor_data:\n",
    "                ax1.plot(timestamps, monitor_data[f'cpu_core_{i}'], \n",
    "                        color=colors[i], alpha=0.7, linewidth=1, label=f'Core {i}')\n",
    "    \n",
    "    ax1.set_xlabel('Time (seconds)')\n",
    "    ax1.set_ylabel('CPU Usage (%)')\n",
    "    ax1.set_title('CPU Core Utilization')\n",
    "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(0, 100)\n",
    "    \n",
    "    # Memory utilization\n",
    "    ax2 = axes[0, 1]\n",
    "    if 'memory_percent' in monitor_data:\n",
    "        ax2.plot(timestamps, monitor_data['memory_percent'], 'g-', linewidth=2, label='Memory %')\n",
    "        ax2_gb = ax2.twinx()\n",
    "        ax2_gb.plot(timestamps, monitor_data['memory_used_gb'], 'g--', linewidth=2, alpha=0.7, label='Memory GB')\n",
    "        ax2_gb.set_ylabel('Memory Usage (GB)', color='g')\n",
    "    \n",
    "    ax2.set_xlabel('Time (seconds)')\n",
    "    ax2.set_ylabel('Memory Usage (%)', color='g')\n",
    "    ax2.set_title('Memory Utilization')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(0, 100)\n",
    "    \n",
    "    # GPU utilization\n",
    "    ax3 = axes[1, 0]\n",
    "    if 'gpu_utilization_percent' in monitor_data and any(monitor_data['gpu_utilization_percent']):\n",
    "        ax3.plot(timestamps, monitor_data['gpu_utilization_percent'], 'r-', linewidth=2, label='GPU Utilization')\n",
    "        ax3_mem = ax3.twinx()\n",
    "        ax3_mem.plot(timestamps, monitor_data['gpu_memory_allocated_gb'], 'r--', linewidth=2, alpha=0.7, label='GPU Memory')\n",
    "        ax3_mem.set_ylabel('GPU Memory (GB)', color='r')\n",
    "        ax3.set_ylabel('GPU Utilization (%)', color='r')\n",
    "        ax3.set_title('GPU Utilization')\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, 'No GPU Data Available', transform=ax3.transAxes, \n",
    "                ha='center', va='center', fontsize=12)\n",
    "        ax3.set_title('GPU Utilization (N/A)')\n",
    "    \n",
    "    ax3.set_xlabel('Time (seconds)')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Summary statistics\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Calculate and display summary stats\n",
    "    summary_text = \"üìä UTILIZATION SUMMARY:\\n\\n\"\n",
    "    \n",
    "    if 'cpu_total' in monitor_data:\n",
    "        cpu_avg = np.mean(monitor_data['cpu_total'])\n",
    "        cpu_max = np.max(monitor_data['cpu_total'])\n",
    "        summary_text += f\"üñ•Ô∏è  CPU:\\n\"\n",
    "        summary_text += f\"   Average: {cpu_avg:.1f}%\\n\"\n",
    "        summary_text += f\"   Peak: {cpu_max:.1f}%\\n\"\n",
    "        \n",
    "        # Count active cores\n",
    "        active_cores = sum(1 for i in range(system_capabilities['cpu']['cpu_count_logical'])\n",
    "                          if f'cpu_core_{i}' in monitor_data and \n",
    "                          np.mean(monitor_data[f'cpu_core_{i}']) > 5.0)\n",
    "        summary_text += f\"   Active Cores: {active_cores}/{system_capabilities['cpu']['cpu_count_logical']}\\n\\n\"\n",
    "    \n",
    "    if 'memory_percent' in monitor_data:\n",
    "        mem_avg = np.mean(monitor_data['memory_percent'])\n",
    "        mem_max_gb = np.max(monitor_data['memory_used_gb'])\n",
    "        summary_text += f\"üíæ Memory:\\n\"\n",
    "        summary_text += f\"   Average: {mem_avg:.1f}%\\n\"\n",
    "        summary_text += f\"   Peak Usage: {mem_max_gb:.1f} GB\\n\\n\"\n",
    "    \n",
    "    if 'gpu_utilization_percent' in monitor_data and any(monitor_data['gpu_utilization_percent']):\n",
    "        gpu_avg = np.mean(monitor_data['gpu_utilization_percent'])\n",
    "        gpu_max_mem = np.max(monitor_data['gpu_memory_allocated_gb'])\n",
    "        summary_text += f\"üéÆ GPU:\\n\"\n",
    "        summary_text += f\"   Average: {gpu_avg:.1f}%\\n\"\n",
    "        summary_text += f\"   Peak Memory: {gpu_max_mem:.1f} GB\\n\"\n",
    "    else:\n",
    "        summary_text += f\"üéÆ GPU: Not Available\\n\"\n",
    "    \n",
    "    ax4.text(0.1, 0.9, summary_text, transform=ax4.transAxes, fontsize=10, \n",
    "            verticalalignment='top', fontfamily='monospace')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Initialize system monitor\n",
    "monitor = SystemMonitor(device)\n",
    "print(\"‚úÖ System monitor initialized\")\n",
    "print(f\"   Monitoring device: {device}\")\n",
    "print(f\"   CPU cores available: {system_capabilities['cpu']['cpu_count_logical']}\")\n",
    "if system_capabilities['gpu']['cuda_available']:\n",
    "    print(f\"   GPU memory available: {system_capabilities['gpu']['gpu_memory_gb'][0]:.1f} GB\")\n",
    "\n",
    "print(f\"\\nüìä Ready for performance monitoring during PMFlow execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb38470",
   "metadata": {},
   "source": [
    "# üß™ Comprehensive Feature Testing\n",
    "\n",
    "Test all PMFlow BNN features with detailed metrics collection for multi-system comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55d9486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Feature Testing\n",
    "def run_comprehensive_pmflow_tests():\n",
    "    \"\"\"Run all PMFlow BNN tests with detailed metrics collection.\"\"\"\n",
    "    \n",
    "    if not library_available:\n",
    "        print(\"‚ùå PMFlow BNN library not available - skipping tests\")\n",
    "        print(\"üìù Run this notebook after library is available locally or from GitHub\")\n",
    "        return None\n",
    "    \n",
    "    print(\"üß™ Starting Comprehensive PMFlow BNN Testing\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Test results storage\n",
    "    test_results = {\n",
    "        'system_info': system_capabilities,\n",
    "        'hardware_profile': hardware_profile,\n",
    "        'config': pmflow_config,\n",
    "        'tests': {}\n",
    "    }\n",
    "    \n",
    "    # Initialize evaluator\n",
    "    evaluator = PMFlowEvaluator(device=device)\n",
    "    \n",
    "    # Test 1: Model Creation and Basic Functionality\n",
    "    print(f\"\\nüèóÔ∏è  Test 1: Model Creation and Basic Functionality\")\n",
    "    try:\n",
    "        monitor.start_monitoring()\n",
    "        \n",
    "        model = get_model_v2(**pmflow_config).to(device)\n",
    "        param_count = sum(p.numel() for p in model.parameters())\n",
    "        \n",
    "        # Test forward pass\n",
    "        test_input = torch.randn(8, 28*28, device=device)\n",
    "        with torch.no_grad():\n",
    "            output = model(test_input)\n",
    "            if isinstance(output, tuple):\n",
    "                logits, hidden = output\n",
    "            else:\n",
    "                logits = output\n",
    "        \n",
    "        monitor_data, timestamps = monitor.stop_monitoring()\n",
    "        \n",
    "        test_results['tests']['model_creation'] = {\n",
    "            'status': 'success',\n",
    "            'param_count': param_count,\n",
    "            'output_shape': list(logits.shape),\n",
    "            'monitor_data': monitor_data,\n",
    "            'timestamps': timestamps\n",
    "        }\n",
    "        \n",
    "        print(f\"   ‚úÖ Model created: {param_count:,} parameters\")\n",
    "        print(f\"   ‚úÖ Forward pass: {test_input.shape} ‚Üí {logits.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        monitor.stop_monitoring()\n",
    "        test_results['tests']['model_creation'] = {\n",
    "            'status': 'failed',\n",
    "            'error': str(e)\n",
    "        }\n",
    "        print(f\"   ‚ùå Model creation failed: {e}\")\n",
    "        return test_results\n",
    "    \n",
    "    # Test 2: Embarrassingly Parallel Scaling\n",
    "    print(f\"\\nüöÄ Test 2: Embarrassingly Parallel Scaling\")\n",
    "    try:\n",
    "        monitor.start_monitoring()\n",
    "        \n",
    "        max_batch = 32 if device.type == 'cuda' else 16\n",
    "        scaling_results = evaluator.evaluate_embarrassingly_parallel_scaling(\n",
    "            model, max_batch_size=max_batch, input_shape=(28*28,)\n",
    "        )\n",
    "        \n",
    "        monitor_data, timestamps = monitor.stop_monitoring()\n",
    "        \n",
    "        test_results['tests']['embarrassingly_parallel'] = {\n",
    "            'status': 'success',\n",
    "            'results': scaling_results,\n",
    "            'monitor_data': monitor_data,\n",
    "            'timestamps': timestamps\n",
    "        }\n",
    "        \n",
    "        print(f\"   ‚úÖ Peak efficiency: {scaling_results['peak_efficiency']:.2f}x\")\n",
    "        print(f\"   ‚úÖ Average efficiency: {scaling_results['average_efficiency']:.2f}x\")\n",
    "        print(f\"   ‚úÖ Embarrassingly parallel: {scaling_results['is_embarrassingly_parallel']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        monitor.stop_monitoring()\n",
    "        test_results['tests']['embarrassingly_parallel'] = {\n",
    "            'status': 'failed', \n",
    "            'error': str(e)\n",
    "        }\n",
    "        print(f\"   ‚ùå Scaling test failed: {e}\")\n",
    "    \n",
    "    # Test 3: Gravitational Center Dynamics\n",
    "    print(f\"\\nüåå Test 3: Gravitational Center Dynamics\")\n",
    "    try:\n",
    "        monitor.start_monitoring()\n",
    "        \n",
    "        # Generate test data\n",
    "        test_data = torch.randn(100, 28*28)\n",
    "        test_labels = torch.randint(0, 4, (100,))\n",
    "        \n",
    "        dynamics_results = evaluator.evaluate_gravitational_dynamics(\n",
    "            model, test_data, test_labels, adaptation_steps=10\n",
    "        )\n",
    "        \n",
    "        monitor_data, timestamps = monitor.stop_monitoring()\n",
    "        \n",
    "        test_results['tests']['gravitational_dynamics'] = {\n",
    "            'status': 'success',\n",
    "            'results': dynamics_results,\n",
    "            'monitor_data': monitor_data,\n",
    "            'timestamps': timestamps\n",
    "        }\n",
    "        \n",
    "        if dynamics_results:\n",
    "            print(f\"   ‚úÖ Center movement: {dynamics_results['mean_movement']:.4f}\")\n",
    "            if 'specialization_ratio' in dynamics_results:\n",
    "                print(f\"   ‚úÖ Specialization ratio: {dynamics_results['specialization_ratio']:.2f}x\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è No gravitational centers detected\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        monitor.stop_monitoring()\n",
    "        test_results['tests']['gravitational_dynamics'] = {\n",
    "            'status': 'failed',\n",
    "            'error': str(e)\n",
    "        }\n",
    "        print(f\"   ‚ùå Gravitational dynamics test failed: {e}\")\n",
    "    \n",
    "    # Test 4: Biological Plasticity\n",
    "    print(f\"\\nüß† Test 4: Biological Plasticity\")\n",
    "    try:\n",
    "        monitor.start_monitoring()\n",
    "        \n",
    "        # Create shifting datasets for plasticity testing\n",
    "        train_data = torch.randn(200, 28*28) * 0.8\n",
    "        train_labels = torch.randint(0, 4, (200,))\n",
    "        \n",
    "        shifting_datasets = []\n",
    "        for i in range(3):\n",
    "            shift_data = torch.randn(100, 28*28) * (0.8 + i * 0.1)\n",
    "            shift_labels = torch.randint(0, 4, (100,))\n",
    "            shifting_datasets.append((shift_data, shift_labels))\n",
    "        \n",
    "        plasticity_results = evaluator.evaluate_biological_plasticity(\n",
    "            model, train_data, train_labels, shifting_datasets\n",
    "        )\n",
    "        \n",
    "        monitor_data, timestamps = monitor.stop_monitoring()\n",
    "        \n",
    "        test_results['tests']['biological_plasticity'] = {\n",
    "            'status': 'success',\n",
    "            'results': plasticity_results,\n",
    "            'monitor_data': monitor_data,\n",
    "            'timestamps': timestamps\n",
    "        }\n",
    "        \n",
    "        print(f\"   ‚úÖ Plasticity score: {plasticity_results['plasticity_score']:.3f}\")\n",
    "        print(f\"   ‚úÖ Memory retention: {plasticity_results['memory_retention']:.3f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        monitor.stop_monitoring()\n",
    "        test_results['tests']['biological_plasticity'] = {\n",
    "            'status': 'failed',\n",
    "            'error': str(e)\n",
    "        }\n",
    "        print(f\"   ‚ùå Plasticity test failed: {e}\")\n",
    "    \n",
    "    # Test 5: Performance Benchmarking\n",
    "    print(f\"\\n‚ö° Test 5: Performance Benchmarking\")\n",
    "    try:\n",
    "        monitor.start_monitoring()\n",
    "        \n",
    "        benchmark_batch_sizes = [4, 8, 16] if device.type == 'cpu' else [8, 16, 32, 64]\n",
    "        \n",
    "        benchmark_results = benchmark_temporal_parallelism(\n",
    "            model, batch_sizes=benchmark_batch_sizes, device=device, num_trials=5\n",
    "        )\n",
    "        \n",
    "        monitor_data, timestamps = monitor.stop_monitoring()\n",
    "        \n",
    "        test_results['tests']['performance_benchmark'] = {\n",
    "            'status': 'success',\n",
    "            'results': benchmark_results,\n",
    "            'monitor_data': monitor_data,\n",
    "            'timestamps': timestamps\n",
    "        }\n",
    "        \n",
    "        print(f\"   ‚úÖ Benchmark completed for {len(benchmark_batch_sizes)} batch sizes\")\n",
    "        print(f\"   ‚úÖ Throughput range: {min(benchmark_results['throughput']):.1f} - {max(benchmark_results['throughput']):.1f} samples/sec\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        monitor.stop_monitoring()\n",
    "        test_results['tests']['performance_benchmark'] = {\n",
    "            'status': 'failed',\n",
    "            'error': str(e)\n",
    "        }\n",
    "        print(f\"   ‚ùå Benchmark failed: {e}\")\n",
    "    \n",
    "    print(f\"\\nüéâ Comprehensive testing complete!\")\n",
    "    return test_results\n",
    "\n",
    "# Run tests if library is available\n",
    "if library_available:\n",
    "    test_results = run_comprehensive_pmflow_tests()\n",
    "else:\n",
    "    print(\"‚è≥ Comprehensive testing pending library availability\")\n",
    "    print(\"üìù This cell will run automatically once the library is imported\")\n",
    "    test_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6e3f8f",
   "metadata": {},
   "source": [
    "# üìä Results Analysis and Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e27737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results Analysis and Reporting\n",
    "def analyze_test_results(test_results):\n",
    "    \"\"\"Analyze and visualize comprehensive test results.\"\"\"\n",
    "    \n",
    "    if test_results is None:\n",
    "        print(\"üìù No test results available - run comprehensive tests first\")\n",
    "        return\n",
    "    \n",
    "    print(\"üìä PMFlow BNN v0.2.0 Library Test Results\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # System Summary\n",
    "    print(f\"\\nüñ•Ô∏è  System Configuration:\")\n",
    "    sys_info = test_results['system_info']\n",
    "    print(f\"   Platform: {sys_info['system']['platform']}\")\n",
    "    print(f\"   CPU Cores: {sys_info['cpu']['cpu_count_logical']} logical, {sys_info['cpu']['cpu_count_physical']} physical\")\n",
    "    print(f\"   Memory: {sys_info['memory']['total_ram_gb']:.1f} GB\")\n",
    "    if sys_info['gpu']['cuda_available']:\n",
    "        print(f\"   GPU: {sys_info['gpu']['gpu_names'][0]} ({sys_info['gpu']['gpu_memory_gb'][0]:.1f} GB)\")\n",
    "    else:\n",
    "        print(f\"   GPU: None (CPU only)\")\n",
    "    print(f\"   Profile: {test_results['hardware_profile']}\")\n",
    "    \n",
    "    # Test Summary\n",
    "    tests = test_results['tests']\n",
    "    passed_tests = sum(1 for test in tests.values() if test['status'] == 'success')\n",
    "    total_tests = len(tests)\n",
    "    success_rate = (passed_tests / total_tests) * 100 if total_tests > 0 else 0\n",
    "    \n",
    "    print(f\"\\n‚úÖ Test Summary:\")\n",
    "    print(f\"   Passed: {passed_tests}/{total_tests} ({success_rate:.1f}%)\")\n",
    "    \n",
    "    # Individual Test Results\n",
    "    for test_name, test_data in tests.items():\n",
    "        status_icon = \"‚úÖ\" if test_data['status'] == 'success' else \"‚ùå\"\n",
    "        print(f\"   {status_icon} {test_name.replace('_', ' ').title()}\")\n",
    "        \n",
    "        if test_data['status'] == 'failed':\n",
    "            print(f\"      Error: {test_data['error']}\")\n",
    "    \n",
    "    # Performance Analysis\n",
    "    print(f\"\\n‚ö° Performance Analysis:\")\n",
    "    \n",
    "    # Embarrassingly Parallel Results\n",
    "    if 'embarrassingly_parallel' in tests and tests['embarrassingly_parallel']['status'] == 'success':\n",
    "        ep_results = tests['embarrassingly_parallel']['results']\n",
    "        print(f\"   üöÄ Embarrassingly Parallel Scaling:\")\n",
    "        print(f\"      Peak Efficiency: {ep_results['peak_efficiency']:.2f}x\")\n",
    "        print(f\"      Average Efficiency: {ep_results['average_efficiency']:.2f}x\")\n",
    "        print(f\"      Is Embarrassingly Parallel: {ep_results['is_embarrassingly_parallel']}\")\n",
    "    \n",
    "    # Gravitational Dynamics\n",
    "    if 'gravitational_dynamics' in tests and tests['gravitational_dynamics']['status'] == 'success':\n",
    "        gd_results = tests['gravitational_dynamics']['results']\n",
    "        if gd_results:\n",
    "            print(f\"   üåå Gravitational Dynamics:\")\n",
    "            print(f\"      Mean Center Movement: {gd_results['mean_movement']:.4f}\")\n",
    "            if 'specialization_ratio' in gd_results:\n",
    "                print(f\"      Specialization Ratio: {gd_results['specialization_ratio']:.2f}x\")\n",
    "    \n",
    "    # Biological Plasticity\n",
    "    if 'biological_plasticity' in tests and tests['biological_plasticity']['status'] == 'success':\n",
    "        bp_results = tests['biological_plasticity']['results']\n",
    "        print(f\"   üß† Biological Plasticity:\")\n",
    "        print(f\"      Plasticity Score: {bp_results['plasticity_score']:.3f}\")\n",
    "        print(f\"      Memory Retention: {bp_results['memory_retention']:.3f}\")\n",
    "    \n",
    "    # Resource Utilization Summary\n",
    "    print(f\"\\nüîß Resource Utilization:\")\n",
    "    for test_name, test_data in tests.items():\n",
    "        if test_data['status'] == 'success' and 'monitor_data' in test_data:\n",
    "            monitor_data = test_data['monitor_data']\n",
    "            if monitor_data and 'cpu_total' in monitor_data and 'memory_percent' in monitor_data:\n",
    "                avg_cpu = sum(monitor_data['cpu_total']) / len(monitor_data['cpu_total'])\n",
    "                avg_memory = sum(monitor_data['memory_percent']) / len(monitor_data['memory_percent'])\n",
    "                print(f\"   {test_name.replace('_', ' ').title()}:\")\n",
    "                print(f\"      CPU: {avg_cpu:.1f}% | Memory: {avg_memory:.1f}%\")\n",
    "                \n",
    "                if 'gpu_utilization_percent' in monitor_data and any(monitor_data['gpu_utilization_percent']):\n",
    "                    avg_gpu = sum(monitor_data['gpu_utilization_percent']) / len(monitor_data['gpu_utilization_percent'])\n",
    "                    avg_gpu_mem = sum(monitor_data['gpu_memory_allocated_gb']) / len(monitor_data['gpu_memory_allocated_gb'])\n",
    "                    print(f\"      GPU: {avg_gpu:.1f}% | GPU Memory: {avg_gpu_mem:.1f} GB\")\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "def visualize_performance_data(test_results):\n",
    "    \"\"\"Create performance visualizations.\"\"\"\n",
    "    \n",
    "    if test_results is None or not any(t['status'] == 'success' for t in test_results['tests'].values()):\n",
    "        print(\"üìä No successful test data available for visualization\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle('PMFlow BNN v0.2.0 Performance Analysis', fontsize=16)\n",
    "        \n",
    "        # 1. Embarrassingly Parallel Scaling\n",
    "        if ('embarrassingly_parallel' in test_results['tests'] and \n",
    "            test_results['tests']['embarrassingly_parallel']['status'] == 'success'):\n",
    "            \n",
    "            ep_results = test_results['tests']['embarrassingly_parallel']['results']\n",
    "            batch_sizes = ep_results['batch_sizes']\n",
    "            scaling_efficiency = ep_results['scaling_efficiency']\n",
    "            \n",
    "            axes[0,0].plot(batch_sizes, scaling_efficiency, 'b-o', linewidth=2, markersize=6)\n",
    "            axes[0,0].axhline(y=1.0, color='r', linestyle='--', alpha=0.7, label='Perfect Linear')\n",
    "            axes[0,0].set_xlabel('Batch Size')\n",
    "            axes[0,0].set_ylabel('Scaling Efficiency')\n",
    "            axes[0,0].set_title('Embarrassingly Parallel Scaling')\n",
    "            axes[0,0].grid(True, alpha=0.3)\n",
    "            axes[0,0].legend()\n",
    "            axes[0,0].set_ylim(0, max(scaling_efficiency) * 1.1)\n",
    "        else:\n",
    "            axes[0,0].text(0.5, 0.5, 'No Scaling Data Available', transform=axes[0,0].transAxes, \n",
    "                          ha='center', va='center', fontsize=12)\n",
    "            axes[0,0].set_title('Embarrassingly Parallel Scaling (N/A)')\n",
    "        \n",
    "        # 2. Resource Utilization Across Tests\n",
    "        test_names = []\n",
    "        cpu_usage = []\n",
    "        memory_usage = []\n",
    "        \n",
    "        for test_name, test_data in test_results['tests'].items():\n",
    "            if test_data['status'] == 'success' and 'monitor_data' in test_data:\n",
    "                monitor_data = test_data['monitor_data']\n",
    "                if monitor_data and 'cpu_total' in monitor_data and 'memory_percent' in monitor_data:\n",
    "                    test_names.append(test_name.replace('_', ' ').title())\n",
    "                    cpu_usage.append(sum(monitor_data['cpu_total']) / len(monitor_data['cpu_total']))\n",
    "                    memory_usage.append(sum(monitor_data['memory_percent']) / len(monitor_data['memory_percent']))\n",
    "        \n",
    "        if test_names:\n",
    "            x_pos = range(len(test_names))\n",
    "            axes[0,1].bar([p - 0.2 for p in x_pos], cpu_usage, 0.4, label='CPU %', alpha=0.8)\n",
    "            axes[0,1].bar([p + 0.2 for p in x_pos], memory_usage, 0.4, label='Memory %', alpha=0.8)\n",
    "            axes[0,1].set_xlabel('Test')\n",
    "            axes[0,1].set_ylabel('Usage %')\n",
    "            axes[0,1].set_title('Resource Utilization by Test')\n",
    "            axes[0,1].set_xticks(x_pos)\n",
    "            axes[0,1].set_xticklabels(test_names, rotation=45, ha='right')\n",
    "            axes[0,1].legend()\n",
    "            axes[0,1].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[0,1].text(0.5, 0.5, 'No Resource Data Available', transform=axes[0,1].transAxes, \n",
    "                          ha='center', va='center', fontsize=12)\n",
    "            axes[0,1].set_title('Resource Utilization (N/A)')\n",
    "        \n",
    "        # 3. Performance Benchmark\n",
    "        if ('performance_benchmark' in test_results['tests'] and \n",
    "            test_results['tests']['performance_benchmark']['status'] == 'success'):\n",
    "            \n",
    "            bench_results = test_results['tests']['performance_benchmark']['results']\n",
    "            batch_sizes = bench_results['batch_sizes']\n",
    "            throughput = bench_results['throughput']\n",
    "            \n",
    "            axes[1,0].plot(batch_sizes, throughput, 'g-s', linewidth=2, markersize=6)\n",
    "            axes[1,0].set_xlabel('Batch Size')\n",
    "            axes[1,0].set_ylabel('Throughput (samples/sec)')\n",
    "            axes[1,0].set_title('Performance Throughput')\n",
    "            axes[1,0].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[1,0].text(0.5, 0.5, 'No Benchmark Data Available', transform=axes[1,0].transAxes, \n",
    "                          ha='center', va='center', fontsize=12)\n",
    "            axes[1,0].set_title('Performance Throughput (N/A)')\n",
    "        \n",
    "        # 4. Test Success Summary\n",
    "        test_statuses = [test['status'] for test in test_results['tests'].values()]\n",
    "        success_count = test_statuses.count('success')\n",
    "        failure_count = test_statuses.count('failed')\n",
    "        \n",
    "        if success_count + failure_count > 0:\n",
    "            labels = ['Passed', 'Failed']\n",
    "            sizes = [success_count, failure_count]\n",
    "            colors = ['#2ecc71', '#e74c3c']\n",
    "            \n",
    "            # Only show pie chart if there are any failures, otherwise show success message\n",
    "            if failure_count > 0:\n",
    "                axes[1,1].pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "            else:\n",
    "                axes[1,1].pie([1], labels=['All Tests Passed'], colors=['#2ecc71'], autopct='100.0%%', startangle=90)\n",
    "            axes[1,1].set_title(f'Test Success Rate ({success_count}/{success_count+failure_count})')\n",
    "        else:\n",
    "            axes[1,1].text(0.5, 0.5, 'No Test Data Available', transform=axes[1,1].transAxes, \n",
    "                          ha='center', va='center', fontsize=12)\n",
    "            axes[1,1].set_title('Test Success Rate (N/A)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"üìä Performance visualizations generated successfully\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"üìä Matplotlib not available - install for visualizations\")\n",
    "    except Exception as e:\n",
    "        print(f\"üìä Visualization error: {e}\")\n",
    "\n",
    "def generate_deployment_report(test_results):\n",
    "    \"\"\"Generate deployment readiness report.\"\"\"\n",
    "    \n",
    "    if test_results is None:\n",
    "        print(\"üìù No test results available for deployment report\")\n",
    "        return\n",
    "    \n",
    "    print(\"üöÄ PMFlow BNN v0.2.0 Deployment Readiness Report\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    tests = test_results['tests']\n",
    "    passed_tests = sum(1 for test in tests.values() if test['status'] == 'success')\n",
    "    total_tests = len(tests)\n",
    "    success_rate = (passed_tests / total_tests) * 100 if total_tests > 0 else 0\n",
    "    \n",
    "    # Deployment readiness assessment\n",
    "    critical_tests = ['model_creation', 'embarrassingly_parallel']\n",
    "    critical_passed = sum(1 for test in critical_tests if test in tests and tests[test]['status'] == 'success')\n",
    "    \n",
    "    deployment_ready = (success_rate >= 80.0 and critical_passed == len(critical_tests))\n",
    "    \n",
    "    print(f\"üìä Overall Status: {'‚úÖ READY FOR DEPLOYMENT' if deployment_ready else '‚ö†Ô∏è NEEDS ATTENTION'}\")\n",
    "    print(f\"üìà Success Rate: {success_rate:.1f}% ({passed_tests}/{total_tests})\")\n",
    "    print(f\"üîß Critical Tests: {critical_passed}/{len(critical_tests)} passed\")\n",
    "    \n",
    "    print(f\"\\nüéØ Next Steps:\")\n",
    "    if deployment_ready:\n",
    "        print(\"   1. ‚úÖ Commit library to GitHub\")\n",
    "        print(\"   2. ‚úÖ Test GitHub import functionality\") \n",
    "        print(\"   3. ‚úÖ Deploy to Jetson Nano for edge testing\")\n",
    "        print(\"   4. ‚úÖ Run cross-system performance validation\")\n",
    "    else:\n",
    "        print(\"   1. ‚ùå Fix failing tests before deployment\")\n",
    "        for test_name, test_data in tests.items():\n",
    "            if test_data['status'] == 'failed':\n",
    "                print(f\"      - {test_name}: {test_data['error']}\")\n",
    "        print(\"   2. ‚ùå Re-run comprehensive tests\")\n",
    "        print(\"   3. ‚ùå Achieve >80% success rate before GitHub deployment\")\n",
    "    \n",
    "    print(f\"\\nüí° Recommendations:\")\n",
    "    \n",
    "    # Performance recommendations\n",
    "    if 'embarrassingly_parallel' in tests and tests['embarrassingly_parallel']['status'] == 'success':\n",
    "        ep_results = tests['embarrassingly_parallel']['results']\n",
    "        if ep_results['peak_efficiency'] < 0.8:\n",
    "            print(f\"   ‚ö° Consider optimizing parallel efficiency (current peak: {ep_results['peak_efficiency']:.2f}x)\")\n",
    "        else:\n",
    "            print(\"   ‚úÖ Excellent parallel scaling achieved\")\n",
    "    \n",
    "    # Resource recommendations\n",
    "    system_info = test_results['system_info']\n",
    "    if system_info['cpu']['cpu_count_logical'] >= 4:\n",
    "        print(\"   üñ•Ô∏è Multi-core system detected - optimal for PMFlow BNN\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è Limited cores detected - consider CPU optimizations\")\n",
    "    \n",
    "    if system_info['gpu']['cuda_available']:\n",
    "        print(\"   üéÆ GPU available - leverage for large-scale testing\")\n",
    "    else:\n",
    "        print(\"   üíª CPU-only system - focus on CPU optimizations\")\n",
    "    \n",
    "    return deployment_ready\n",
    "\n",
    "# Run analysis if test results are available\n",
    "if 'test_results' in locals() and test_results is not None:\n",
    "    print(\"üîç Analyzing test results...\")\n",
    "    analyzed_results = analyze_test_results(test_results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    visualize_performance_data(test_results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    deployment_ready = generate_deployment_report(test_results)\n",
    "else:\n",
    "    print(\"‚è≥ Results analysis pending comprehensive test completion\")\n",
    "    print(\"üìù This analysis will run automatically after comprehensive testing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
