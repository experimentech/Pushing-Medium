from tqdm import tqdm  # add this import at the top of the file

def train_epoch_bnn(model, opt, loader, device, T=5, plasticity_every=2, epoch_idx=1, total_epochs=1):
    model.train()
    total, correct, loss_sum = 0, 0, 0.0
    pbar = tqdm(enumerate(loader, 1), total=len(loader),
                desc=f"[Epoch {epoch_idx}/{total_epochs}] BNN train", ncols=100)
    for step, (x, y) in pbar:
        x, y = x.to(device), y.to(device)
        opt.zero_grad()
        logits, (z, h) = model(x, T=T)
        loss = F.cross_entropy(logits, y)
        loss.backward()
        opt.step()

        # Interleave local unsupervised plasticity
        if step % plasticity_every == 0:
            with torch.no_grad():
                z, h, _ = model.step(model.enc(x),
                                     torch.zeros(x.size(0), model.readout.in_features, device=device))
                pm_local_plasticity(model.pm, z, h)

        loss_sum += loss.item() * x.size(0)
        correct += (logits.argmax(1) == y).sum().item()
        total += x.size(0)

        # Update progress bar postfix
        pbar.set_postfix(loss=f"{loss_sum/total:.4f}", acc=f"{correct/total:.3f}")

    return loss_sum/total, correct/total


def train_epoch_baseline(model, opt, loader, device, label="Baseline", epoch_idx=1, total_epochs=1):
    model.train()
    total, correct, loss_sum = 0, 0, 0.0
    pbar = tqdm(enumerate(loader, 1), total=len(loader),
                desc=f"[Epoch {epoch_idx}/{total_epochs}] {label} train", ncols=100)
    for step, (x, y) in pbar:
        x, y = x.to(device), y.to(device)
        opt.zero_grad()
        logits = model(x)
        loss = F.cross_entropy(logits, y)
        loss.backward()
        opt.step()

        loss_sum += loss.item() * x.size(0)
        correct += (logits.argmax(1) == y).sum().item()
        total += x.size(0)

        pbar.set_postfix(loss=f"{loss_sum/total:.4f}", acc=f"{correct/total:.3f}")

    return loss_sum/total, correct/total
    
    ===============================================
    
    for ep in range(1, epochs+1):
    tr_bnn_loss, tr_bnn_acc = train_epoch_bnn(bnn, opt_bnn, train_loader, device,
                                              T=5, plasticity_every=2,
                                              epoch_idx=ep, total_epochs=epochs)
    tr_cnn_loss, tr_cnn_acc = train_epoch_baseline(cnn, opt_cnn, train_loader, device,
                                                   label="CNN", epoch_idx=ep, total_epochs=epochs)
    tr_gru_loss, tr_gru_acc = train_epoch_baseline(gru, opt_gru, train_loader, device,
                                                   label="GRU", epoch_idx=ep, total_epochs=epochs)

    # ... rest of your eval/print code ...


