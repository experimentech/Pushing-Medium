{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51c85de5",
   "metadata": {},
   "source": [
    "# MNIST PMFlow Benchmark - Interactive Notebook\n",
    "\n",
    "This notebook compares baseline CNN with PMFlow-enhanced neural networks on MNIST classification. Perfect for testing GPU acceleration and parallelism on Jetson Nano.\n",
    "\n",
    "## Features\n",
    "- **GPU Acceleration**: CUDA-optimized for Jetson Nano\n",
    "- **Interactive Progress**: Real-time training visualization\n",
    "- **Parallel Training**: Side-by-side model comparison\n",
    "- **PMFlow Integration**: Pushing-medium flow blocks in neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1101f23d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fecbcd5dc5c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# GPU Detection and Environment Setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import threading\n",
    "\n",
    "# Check GPU availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"CUDA not available - using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0517378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PMFlow Block Implementation\n",
    "class PMFlow(nn.Module):\n",
    "    \"\"\"\n",
    "    Pushing-Medium Flow block that simulates gravitational effects in latent space\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim=16, centers=None, mus=None, steps=3, dt=0.1):\n",
    "        super().__init__()\n",
    "        if centers is None:\n",
    "            centers = torch.randn(4, latent_dim) * 0.5\n",
    "        if mus is None:\n",
    "            mus = torch.ones(len(centers)) * 0.5\n",
    "        \n",
    "        self.centers = nn.Parameter(torch.tensor(centers, dtype=torch.float32))\n",
    "        self.mus = nn.Parameter(torch.tensor(mus, dtype=torch.float32))\n",
    "        self.steps = steps\n",
    "        self.dt = dt\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"Apply pushing-medium flow transformation\"\"\"\n",
    "        for _ in range(self.steps):\n",
    "            # Calculate refractive index n = 1 + sum(mu/r)\n",
    "            n = torch.ones(z.size(0), device=z.device)\n",
    "            grad = torch.zeros_like(z)\n",
    "            \n",
    "            for c, mu in zip(self.centers, self.mus):\n",
    "                rvec = z - c\n",
    "                r = torch.norm(rvec, dim=1) + 1e-4  # Avoid division by zero\n",
    "                n = n + mu / r\n",
    "                grad = grad + (-mu) * rvec / (r.unsqueeze(1)**3)\n",
    "            \n",
    "            # Flow step: z += dt * grad(ln n)\n",
    "            grad_ln_n = grad / n.unsqueeze(1)\n",
    "            z = z + self.dt * grad_ln_n\n",
    "        \n",
    "        return z\n",
    "\n",
    "# Test PMFlow block\n",
    "print(\"Testing PMFlow block...\")\n",
    "pmflow = PMFlow(latent_dim=8).to(device)\n",
    "test_input = torch.randn(32, 8).to(device)\n",
    "test_output = pmflow(test_input)\n",
    "print(f\"Input shape: {test_input.shape}, Output shape: {test_output.shape}\")\n",
    "print(\"PMFlow block initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9feb359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Models\n",
    "class PMNet(nn.Module):\n",
    "    \"\"\"Neural network with optional PMFlow block\"\"\"\n",
    "    def __init__(self, use_flow=True, latent_dim=16):\n",
    "        super().__init__()\n",
    "        self.use_flow = use_flow\n",
    "        \n",
    "        # Encoder: 28x28 -> latent_dim\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 256), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, latent_dim)\n",
    "        )\n",
    "        \n",
    "        # Optional PMFlow block\n",
    "        self.flow = PMFlow(latent_dim=latent_dim) if use_flow else None\n",
    "        \n",
    "        # Classification head\n",
    "        self.head = nn.Linear(latent_dim, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.enc(x)\n",
    "        if self.flow is not None:\n",
    "            z = self.flow(z)\n",
    "        return self.head(z)\n",
    "\n",
    "# Create models\n",
    "print(\"Creating models...\")\n",
    "model_baseline = PMNet(use_flow=False, latent_dim=16).to(device)\n",
    "model_pmflow = PMNet(use_flow=True, latent_dim=16).to(device)\n",
    "\n",
    "# Count parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "baseline_params = count_parameters(model_baseline)\n",
    "pmflow_params = count_parameters(model_pmflow)\n",
    "\n",
    "print(f\"Baseline model parameters: {baseline_params:,}\")\n",
    "print(f\"PMFlow model parameters: {pmflow_params:,}\")\n",
    "print(f\"PMFlow overhead: {pmflow_params - baseline_params:,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f26359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading with Parallel Workers\n",
    "def setup_data_loaders(batch_size=128, num_workers=2):\n",
    "    \"\"\"Setup MNIST data loaders with parallel processing\"\"\"\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    # Download and load datasets\n",
    "    print(\"Loading MNIST dataset...\")\n",
    "    train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "    \n",
    "    # Create data loaders with parallel workers\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size*2, \n",
    "        shuffle=False, \n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Setup data loaders\n",
    "# Adjust num_workers based on your system (Jetson Nano: 2-4 workers optimal)\n",
    "train_loader, test_loader = setup_data_loaders(batch_size=128, num_workers=2)\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "print(f\"Total training samples: {len(train_loader.dataset)}\")\n",
    "print(f\"Total test samples: {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672aebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Evaluation Functions\n",
    "def train_epoch(model, optimizer, loader, device, desc=\"Training\"):\n",
    "    \"\"\"Train model for one epoch with progress tracking\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(loader, desc=desc, leave=False)\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(progress_bar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        total += target.size(0)\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    return total_loss / len(loader), correct / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, loader, device, desc=\"Evaluating\"):\n",
    "    \"\"\"Evaluate model with progress tracking\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(loader, desc=desc, leave=False)\n",
    "    \n",
    "    for data, target in progress_bar:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        total += target.size(0)\n",
    "        \n",
    "        progress_bar.set_postfix({'Acc': f'{100.*correct/total:.2f}%'})\n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "print(\"Training and evaluation functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53c877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time Visualization Setup\n",
    "class LivePlotter:\n",
    "    \"\"\"Real-time plotting for training progress\"\"\"\n",
    "    def __init__(self):\n",
    "        self.fig, (self.ax1, self.ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        self.baseline_train_acc = []\n",
    "        self.baseline_test_acc = []\n",
    "        self.pmflow_train_acc = []\n",
    "        self.pmflow_test_acc = []\n",
    "        self.epochs = []\n",
    "        \n",
    "    def update(self, epoch, baseline_train, baseline_test, pmflow_train, pmflow_test):\n",
    "        \"\"\"Update plots with new data\"\"\"\n",
    "        self.epochs.append(epoch)\n",
    "        self.baseline_train_acc.append(baseline_train)\n",
    "        self.baseline_test_acc.append(baseline_test)\n",
    "        self.pmflow_train_acc.append(pmflow_train)\n",
    "        self.pmflow_test_acc.append(pmflow_test)\n",
    "        \n",
    "        # Clear and redraw\n",
    "        self.ax1.clear()\n",
    "        self.ax2.clear()\n",
    "        \n",
    "        # Training accuracy\n",
    "        self.ax1.plot(self.epochs, self.baseline_train_acc, 'bo--', label='Baseline Train', alpha=0.7)\n",
    "        self.ax1.plot(self.epochs, self.pmflow_train_acc, 'r^--', label='PMFlow Train', alpha=0.7)\n",
    "        self.ax1.set_title(\"Training Accuracy\")\n",
    "        self.ax1.set_xlabel(\"Epoch\")\n",
    "        self.ax1.set_ylabel(\"Accuracy\")\n",
    "        self.ax1.legend()\n",
    "        self.ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Test accuracy\n",
    "        self.ax2.plot(self.epochs, self.baseline_test_acc, 'bo-', label='Baseline Test')\n",
    "        self.ax2.plot(self.epochs, self.pmflow_test_acc, 'r^-', label='PMFlow Test')\n",
    "        self.ax2.set_title(\"Test Accuracy\")\n",
    "        self.ax2.set_xlabel(\"Epoch\")\n",
    "        self.ax2.set_ylabel(\"Accuracy\")\n",
    "        self.ax2.legend()\n",
    "        self.ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        self.fig.suptitle(\"MNIST: Baseline vs PMFlow - Live Training Progress\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Initialize live plotter\n",
    "plotter = LivePlotter()\n",
    "print(\"Live plotting system ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e362f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel Training Configuration\n",
    "class ParallelTrainer:\n",
    "    \"\"\"Train both models in parallel for fair comparison\"\"\"\n",
    "    def __init__(self, model_baseline, model_pmflow, device):\n",
    "        self.model_baseline = model_baseline\n",
    "        self.model_pmflow = model_pmflow\n",
    "        self.device = device\n",
    "        \n",
    "        # Optimizers\n",
    "        self.opt_baseline = torch.optim.Adam(model_baseline.parameters(), lr=1e-3)\n",
    "        self.opt_pmflow = torch.optim.Adam(model_pmflow.parameters(), lr=1e-3)\n",
    "        \n",
    "        # Training history\n",
    "        self.history = {\n",
    "            'baseline_train': [], 'baseline_test': [],\n",
    "            'pmflow_train': [], 'pmflow_test': []\n",
    "        }\n",
    "    \n",
    "    def train_epoch_parallel(self, train_loader, test_loader, epoch):\n",
    "        \"\"\"Train both models for one epoch\"\"\"\n",
    "        print(f\"\\\\n=== Epoch {epoch} ===\")\n",
    "        \n",
    "        # Train baseline model\n",
    "        start_time = time.time()\n",
    "        train_loss_b, train_acc_b = train_epoch(\n",
    "            self.model_baseline, self.opt_baseline, train_loader, \n",
    "            self.device, desc=f\"Baseline Epoch {epoch}\"\n",
    "        )\n",
    "        test_acc_b = evaluate_model(\n",
    "            self.model_baseline, test_loader, self.device, \n",
    "            desc=f\"Baseline Test {epoch}\"\n",
    "        )\n",
    "        baseline_time = time.time() - start_time\n",
    "        \n",
    "        # Train PMFlow model\n",
    "        start_time = time.time()\n",
    "        train_loss_p, train_acc_p = train_epoch(\n",
    "            self.model_pmflow, self.opt_pmflow, train_loader, \n",
    "            self.device, desc=f\"PMFlow Epoch {epoch}\"\n",
    "        )\n",
    "        test_acc_p = evaluate_model(\n",
    "            self.model_pmflow, test_loader, self.device, \n",
    "            desc=f\"PMFlow Test {epoch}\"\n",
    "        )\n",
    "        pmflow_time = time.time() - start_time\n",
    "        \n",
    "        # Store results\n",
    "        self.history['baseline_train'].append(train_acc_b)\n",
    "        self.history['baseline_test'].append(test_acc_b)\n",
    "        self.history['pmflow_train'].append(train_acc_p)\n",
    "        self.history['pmflow_test'].append(test_acc_p)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"Baseline: Train={train_acc_b:.4f}, Test={test_acc_b:.4f}, Time={baseline_time:.1f}s\")\n",
    "        print(f\"PMFlow:   Train={train_acc_p:.4f}, Test={test_acc_p:.4f}, Time={pmflow_time:.1f}s\")\n",
    "        \n",
    "        return train_acc_b, test_acc_b, train_acc_p, test_acc_p\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = ParallelTrainer(model_baseline, model_pmflow, device)\n",
    "print(\"Parallel trainer ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6303ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Training Loop\n",
    "def run_training(epochs=10, live_plot=True):\n",
    "    \"\"\"Run interactive training with real-time visualization\"\"\"\n",
    "    print(f\"Starting training for {epochs} epochs on {device}\")\n",
    "    print(f\"Dataset size: {len(train_loader.dataset)} training, {len(test_loader.dataset)} test\")\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Train both models\n",
    "        baseline_train, baseline_test, pmflow_train, pmflow_test = trainer.train_epoch_parallel(\n",
    "            train_loader, test_loader, epoch\n",
    "        )\n",
    "        \n",
    "        # Update live plot\n",
    "        if live_plot:\n",
    "            clear_output(wait=True)\n",
    "            plotter.update(epoch, baseline_train, baseline_test, pmflow_train, pmflow_test)\n",
    "        \n",
    "        # GPU memory check (for Jetson Nano monitoring)\n",
    "        if torch.cuda.is_available():\n",
    "            memory_used = torch.cuda.memory_allocated() / 1e9\n",
    "            memory_total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "            print(f\"GPU Memory: {memory_used:.1f}/{memory_total:.1f} GB\")\n",
    "    \n",
    "    print(\"\\\\n=== Training Complete! ===\")\n",
    "    \n",
    "    # Final results\n",
    "    final_baseline = trainer.history['baseline_test'][-1]\n",
    "    final_pmflow = trainer.history['pmflow_test'][-1]\n",
    "    improvement = final_pmflow - final_baseline\n",
    "    \n",
    "    print(f\"Final Test Accuracy:\")\n",
    "    print(f\"  Baseline: {final_baseline:.4f}\")\n",
    "    print(f\"  PMFlow:   {final_pmflow:.4f}\")\n",
    "    print(f\"  Improvement: {improvement:+.4f} ({improvement*100:+.2f}%)\")\n",
    "    \n",
    "    return trainer.history\n",
    "\n",
    "# Configuration\n",
    "EPOCHS = 10  # Adjust for your testing needs\n",
    "LIVE_PLOTTING = True  # Set to False if plotting causes issues\n",
    "\n",
    "print(\"Ready to start training!\")\n",
    "print(\"Run the next cell to begin the interactive training process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2e1bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 START TRAINING\n",
    "# Execute this cell to begin the benchmark training\n",
    "history = run_training(epochs=EPOCHS, live_plot=LIVE_PLOTTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa25271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-Training Analysis and Visualization\n",
    "def analyze_results(history):\n",
    "    \"\"\"Comprehensive analysis of training results\"\"\"\n",
    "    \n",
    "    # Create final visualization\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    epochs = range(1, len(history['baseline_test']) + 1)\n",
    "    \n",
    "    # Training accuracy comparison\n",
    "    ax1.plot(epochs, history['baseline_train'], 'bo--', label='Baseline', alpha=0.7)\n",
    "    ax1.plot(epochs, history['pmflow_train'], 'r^--', label='PMFlow', alpha=0.7)\n",
    "    ax1.set_title(\"Training Accuracy\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Test accuracy comparison\n",
    "    ax2.plot(epochs, history['baseline_test'], 'bo-', label='Baseline')\n",
    "    ax2.plot(epochs, history['pmflow_test'], 'r^-', label='PMFlow')\n",
    "    ax2.set_title(\"Test Accuracy\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Improvement over time\n",
    "    improvements = [p - b for p, b in zip(history['pmflow_test'], history['baseline_test'])]\n",
    "    ax3.plot(epochs, improvements, 'go-', alpha=0.7)\n",
    "    ax3.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "    ax3.set_title(\"PMFlow Improvement vs Baseline\")\n",
    "    ax3.set_xlabel(\"Epoch\")\n",
    "    ax3.set_ylabel(\"Accuracy Difference\")\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Final comparison bar chart\n",
    "    final_scores = [history['baseline_test'][-1], history['pmflow_test'][-1]]\n",
    "    ax4.bar(['Baseline', 'PMFlow'], final_scores, color=['blue', 'red'], alpha=0.7)\n",
    "    ax4.set_title(\"Final Test Accuracy\")\n",
    "    ax4.set_ylabel(\"Accuracy\")\n",
    "    ax4.set_ylim([min(final_scores) - 0.01, max(final_scores) + 0.01])\n",
    "    \n",
    "    # Add values on bars\n",
    "    for i, v in enumerate(final_scores):\n",
    "        ax4.text(i, v + 0.002, f'{v:.4f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"MNIST PMFlow Benchmark Results\", y=1.02, fontsize=16)\n",
    "    plt.show()\n",
    "    \n",
    "    # Performance summary\n",
    "    print(\"\\\\n\" + \"=\"*50)\n",
    "    print(\"PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    baseline_final = history['baseline_test'][-1]\n",
    "    pmflow_final = history['pmflow_test'][-1]\n",
    "    improvement = pmflow_final - baseline_final\n",
    "    improvement_pct = improvement * 100\n",
    "    \n",
    "    print(f\"Final Test Accuracy:\")\n",
    "    print(f\"  Baseline: {baseline_final:.4f} ({baseline_final*100:.2f}%)\")\n",
    "    print(f\"  PMFlow:   {pmflow_final:.4f} ({pmflow_final*100:.2f}%)\")\n",
    "    print(f\"  Improvement: {improvement:+.4f} ({improvement_pct:+.2f} percentage points)\")\n",
    "    \n",
    "    # Additional metrics\n",
    "    baseline_best = max(history['baseline_test'])\n",
    "    pmflow_best = max(history['pmflow_test'])\n",
    "    \n",
    "    print(f\"\\\\nBest Test Accuracy Achieved:\")\n",
    "    print(f\"  Baseline: {baseline_best:.4f}\")\n",
    "    print(f\"  PMFlow:   {pmflow_best:.4f}\")\n",
    "    \n",
    "    print(f\"\\\\nModel Parameter Count:\")\n",
    "    print(f\"  Baseline: {count_parameters(model_baseline):,}\")\n",
    "    print(f\"  PMFlow:   {count_parameters(model_pmflow):,}\")\n",
    "    print(f\"  Overhead: {count_parameters(model_pmflow) - count_parameters(model_baseline):,}\")\n",
    "\n",
    "print(\"Analysis functions ready. Run analyze_results(history) after training completes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78488079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 ANALYZE RESULTS\n",
    "# Execute this cell after training to see comprehensive analysis\n",
    "analyze_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c7fc07",
   "metadata": {},
   "source": [
    "## 🔧 Jetson Nano Optimization Tips\n",
    "\n",
    "### GPU Memory Management\n",
    "- Monitor GPU memory usage during training\n",
    "- Reduce batch size if you encounter OOM errors\n",
    "- Use `torch.cuda.empty_cache()` between experiments\n",
    "\n",
    "### Performance Tuning\n",
    "- **Optimal batch size for Jetson Nano**: 64-128\n",
    "- **Data loader workers**: 2-4 (adjust based on CPU cores)\n",
    "- **Mixed precision**: Consider using `torch.cuda.amp` for faster training\n",
    "\n",
    "### Parallel Processing\n",
    "- The notebook uses parallel data loading\n",
    "- Both models train sequentially for fair comparison\n",
    "- Consider training on different GPU streams for true parallelism\n",
    "\n",
    "### Troubleshooting\n",
    "- If plots don't update: Set `LIVE_PLOTTING = False`\n",
    "- If training is slow: Reduce epochs or use smaller models\n",
    "- If memory issues: Reduce batch size or use CPU (`device = \"cpu\"`)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
